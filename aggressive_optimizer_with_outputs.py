"""
æ¿€è¿›ä¼˜åŒ–ç‰ˆæœ¬ - æ›´å¤šç«™ç‚¹ç§»åŠ¨ï¼Œæ›´é«˜è¦†ç›–ç‡æå‡
åŸºäºæˆåŠŸç®—æ³•ï¼Œè°ƒæ•´å‚æ•°ä»¥å®ç°æ›´å¤§å¹…åº¦çš„ä¼˜åŒ–
"""

import numpy as np
import pandas as pd
from numba import jit, prange
import logging
import time
from typing import Dict, Any, Tuple
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
import json

try:
    import geopandas as gpd
    HAS_GEOPANDAS = True
except ImportError:
    HAS_GEOPANDAS = False
    print("Warning: GeoPandas not available, will create CSV files instead")

from data_preprocessing import DataProcessor
from acceleration_utils import fast_population_coverage

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@jit(nopython=True, cache=True)
def aggressive_initialization(original_positions: np.ndarray,
                            population_size: int,
                            max_move_ratio: float = 0.4,  # å¢åŠ åˆ°40%
                            max_move_distance: float = 0.008) -> np.ndarray:  # å¢åŠ ç§»åŠ¨è·ç¦»
    """
    æ¿€è¿›åˆå§‹åŒ–ï¼šæ›´å¤šç«™ç‚¹ç§»åŠ¨ï¼Œæ›´å¤§ç§»åŠ¨èŒƒå›´
    - æ¯ä¸ªä¸ªä½“ç§»åŠ¨20-40%çš„ç«™ç‚¹
    - å…è®¸æ›´å¤§çš„ç§»åŠ¨è·ç¦»
    """
    n_stops = original_positions.shape[0]
    population = np.zeros((population_size, n_stops, 2))
    
    for i in range(population_size):
        population[i] = original_positions.copy()
        
        # æ¯ä¸ªä¸ªä½“ç§»åŠ¨20-40%çš„ç«™ç‚¹
        min_move_ratio = 0.2  # æœ€å°‘ç§»åŠ¨20%
        move_ratio = min_move_ratio + np.random.random() * (max_move_ratio - min_move_ratio)
        n_move = max(1, int(n_stops * move_ratio))
        move_indices = np.random.choice(n_stops, n_move, replace=False)
        
        for idx in move_indices:
            # æ›´å¤§çš„ç§»åŠ¨èŒƒå›´ï¼šè·ç¦»æŒ‰ä¼½é©¬åˆ†å¸ƒ
            move_distance = np.random.gamma(2.0, max_move_distance * 0.4)
            move_distance = min(move_distance, max_move_distance)
            
            # éšæœºæ–¹å‘
            angle = np.random.random() * 2 * np.pi
            dx = move_distance * np.cos(angle)
            dy = move_distance * np.sin(angle)
            
            population[i, idx, 0] += dx
            population[i, idx, 1] += dy
    
    return population

@jit(nopython=True, cache=True)
def coverage_focused_fitness(positions: np.ndarray,
                           original_positions: np.ndarray,
                           pop_points: np.ndarray,
                           pop_weights: np.ndarray,
                           coverage_radius: float) -> float:
    """
    è¦†ç›–ç‡å¯¼å‘é€‚åº”åº¦å‡½æ•°
    ä¸»è¦ä¼˜åŒ–ç›®æ ‡ï¼šè¦†ç›–ç‡ >> ç¨³å®šæ€§
    """
    n_stops = positions.shape[0]
    
    # 1. è¦†ç›–ç‡è®¡ç®— - ä¸»è¦ç›®æ ‡
    coverage_rate = fast_population_coverage(
        positions, pop_points, pop_weights, coverage_radius
    )
    
    # 2. ç§»åŠ¨æƒ©ç½š - è¾ƒè½»çš„æƒ©ç½š
    total_movement = 0.0
    severe_move_penalty = 0.0
    
    for i in range(n_stops):
        dx = positions[i, 0] - original_positions[i, 0]
        dy = positions[i, 1] - original_positions[i, 1]
        movement = np.sqrt(dx * dx + dy * dy)
        
        total_movement += movement
        
        # åªå¯¹è¿‡åº¦ç§»åŠ¨è¿›è¡Œä¸¥å‰æƒ©ç½š
        if movement > 0.015:  # è¶…è¿‡~1.65å…¬é‡Œæ‰ä¸¥å‰æƒ©ç½š
            severe_move_penalty += movement * 5.0
        else:
            # æ­£å¸¸ç§»åŠ¨åªæœ‰è½»å¾®æƒ©ç½š
            severe_move_penalty += movement * 0.5
    
    # 3. åˆ†æ•£æ€§å¥–åŠ± - é¿å…ç«™ç‚¹è¿‡äºé›†ä¸­
    dispersion_bonus = 0.0
    if n_stops > 1:
        min_distances = np.full(n_stops, np.inf)
        for i in range(n_stops):
            for j in range(n_stops):
                if i != j:
                    dist = np.sqrt((positions[i, 0] - positions[j, 0])**2 + 
                                 (positions[i, 1] - positions[j, 1])**2)
                    min_distances[i] = min(min_distances[i], dist)
        
        avg_min_distance = np.mean(min_distances)
        dispersion_bonus = avg_min_distance * 2.0  # é¼“åŠ±é€‚å½“åˆ†æ•£
    
    # ç»¼åˆé€‚åº”åº¦ï¼šè¦†ç›–ç‡æƒé‡æœ€å¤§
    fitness = (
        coverage_rate * 20.0 +           # è¦†ç›–ç‡æƒé‡æé«˜
        dispersion_bonus * 3.0 -         # åˆ†æ•£æ€§å¥–åŠ±
        severe_move_penalty * 1.0        # ç§»åŠ¨æƒ©ç½šç›¸å¯¹è¾ƒè½»
    )
    
    return fitness

@jit(nopython=True, cache=True)
def intensive_genetic_algorithm(original_positions: np.ndarray,
                              pop_points: np.ndarray,
                              pop_weights: np.ndarray,
                              coverage_radius: float,
                              population_size: int = 80,  # å¢å¤§ç§ç¾¤
                              max_generations: int = 200) -> Tuple[np.ndarray, float]:  # å¢åŠ ä»£æ•°
    """å¼ºåŒ–é—ä¼ ç®—æ³• - æ›´æ¿€è¿›çš„ä¼˜åŒ–"""
    
    # æ¿€è¿›åˆå§‹åŒ–
    population = aggressive_initialization(original_positions, population_size, 
                                         max_move_ratio=0.4, max_move_distance=0.008)
    
    best_individual = population[0].copy()
    best_fitness = coverage_focused_fitness(
        best_individual, original_positions, pop_points, pop_weights, coverage_radius
    )
    
    stagnation_count = 0
    last_best_fitness = best_fitness
    
    for generation in range(max_generations):
        # è®¡ç®—é€‚åº”åº¦
        fitness_scores = np.zeros(population_size)
        
        for i in range(population_size):
            fitness_scores[i] = coverage_focused_fitness(
                population[i], original_positions, pop_points, pop_weights, coverage_radius
            )
            
            if fitness_scores[i] > best_fitness:
                best_fitness = fitness_scores[i]
                best_individual = population[i].copy()
                stagnation_count = 0
            
        # åŠ¨æ€æ—©åœç­–ç•¥
        if abs(best_fitness - last_best_fitness) < 0.001:
            stagnation_count += 1
        else:
            stagnation_count = 0
        
        if stagnation_count > 30:  # æ›´å®½æ¾çš„æ—©åœ
            break
        
        last_best_fitness = best_fitness
        
        # é€‰æ‹©æ’åº
        sorted_indices = np.argsort(fitness_scores)[::-1]
        
        # ç²¾è‹±ä¿ç•™ - ä¿ç•™æ›´å¤šç²¾è‹±
        elite_size = max(5, population_size // 8)
        new_population = np.zeros_like(population)
        
        for i in range(elite_size):
            new_population[i] = population[sorted_indices[i]].copy()
        
        # ç”Ÿæˆæ–°ä¸ªä½“
        for i in range(elite_size, population_size):
            # é”¦æ ‡èµ›é€‰æ‹© - é€‰æ‹©èŒƒå›´æ›´å¤§
            parent1_idx = sorted_indices[np.random.randint(0, min(10, population_size))]
            parent2_idx = sorted_indices[np.random.randint(0, min(10, population_size))]
            
            # æ›´æ¿€è¿›çš„äº¤å‰
            child = population[parent1_idx].copy()
            
            # å¯¹20-30%çš„ç«™ç‚¹è¿›è¡Œäº¤å‰
            crossover_ratio = 0.2 + np.random.random() * 0.1
            n_crossover = max(1, int(original_positions.shape[0] * crossover_ratio))
            crossover_indices = np.random.choice(
                original_positions.shape[0], n_crossover, replace=False
            )
            
            for idx in crossover_indices:
                if np.random.random() < 0.6:  # å¢åŠ äº¤å‰æ¦‚ç‡
                    child[idx] = population[parent2_idx, idx].copy()
            
            # æ›´é¢‘ç¹çš„å˜å¼‚
            if np.random.random() < 0.5:  # å¢åŠ å˜å¼‚æ¦‚ç‡
                n_mutate = max(1, int(original_positions.shape[0] * 0.15))  # å¢åŠ å˜å¼‚æ•°é‡
                mutate_indices = np.random.choice(
                    original_positions.shape[0], n_mutate, replace=False
                )
                
                for idx in mutate_indices:
                    # æ›´å¤§çš„å˜å¼‚å¼ºåº¦
                    dx = np.random.normal(0, 0.003)  # å¢å¤§å˜å¼‚èŒƒå›´
                    dy = np.random.normal(0, 0.003)
                    child[idx, 0] += dx
                    child[idx, 1] += dy
            
            new_population[i] = child
        
        population = new_population
    
    return best_individual, best_fitness

class AggressiveOptimizerWithOutputs:
    """æ¿€è¿›ä¼˜åŒ–å™¨ - æ›´é«˜è¦†ç›–ç‡ç‰ˆæœ¬"""
    
    def __init__(self, population_csv_path: str, bus_stops_shp_path: str):
        """åˆå§‹åŒ–"""
        logger.info("ğŸš€ åˆå§‹åŒ–æ¿€è¿›ä¼˜åŒ–å™¨ï¼ˆé«˜è¦†ç›–ç‡ç‰ˆï¼‰...")
        
        self.coverage_radius = 400  # å¢åŠ è¦†ç›–åŠå¾„åˆ°400ç±³
        
        # æ•°æ®é¢„å¤„ç†
        self.processor = DataProcessor(population_csv_path, bus_stops_shp_path)
        self.population_data, self.bus_stops_data, self.overlap_info = self.processor.get_processed_data()
        
        logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ:")
        logger.info(f"   äººå£ç½‘æ ¼: {len(self.population_data):,}")
        logger.info(f"   å…¬äº¤ç«™ç‚¹: {len(self.bus_stops_data):,}")
        logger.info(f"   è¦†ç›–åŠå¾„: {self.coverage_radius}ç±³ï¼ˆå¢å¼ºç‰ˆï¼‰")
        
        self.output_dir = None
    
    def optimize_and_save_results(self) -> str:
        """æ‰§è¡Œæ¿€è¿›ä¼˜åŒ–å¹¶ä¿å­˜å®Œæ•´ç»“æœ"""
        logger.info("ğŸ¯ å¼€å§‹æ¿€è¿›ä¼˜åŒ–ï¼ˆç›®æ ‡ï¼šæœ€å¤§åŒ–è¦†ç›–ç‡ï¼‰...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = Path(f"aggressive_optimization_results_{timestamp}")
        self.output_dir.mkdir(exist_ok=True)
        
        logger.info(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {self.output_dir}")
        
        # æ•°æ®å‡†å¤‡
        original_positions = self.bus_stops_data[['longitude', 'latitude']].values
        pop_points = self.population_data[['longitude', 'latitude']].values
        pop_weights = self.population_data['population'].values
        
        # æ‰§è¡Œæ¿€è¿›ä¼˜åŒ–
        logger.info("âš¡ æ‰§è¡Œå¼ºåŒ–é—ä¼ ç®—æ³•ä¼˜åŒ–...")
        logger.info("   ğŸ¯ ç›®æ ‡ï¼šç§»åŠ¨æ›´å¤šç«™ç‚¹ï¼Œæ˜¾è‘—æå‡è¦†ç›–ç‡")
        logger.info("   ğŸ“ˆ é¢„æœŸç§»åŠ¨æ¯”ä¾‹: 25-40%")
        logger.info("   ğŸ”„ ç®—æ³•å¼ºåº¦: åŠ å¼ºç‰ˆ")
        
        start_time = time.time()
        
        optimized_positions, best_fitness = intensive_genetic_algorithm(
            original_positions, pop_points, pop_weights, 
            self.coverage_radius / 111320.0,  # è½¬æ¢ä¸ºåº¦
            population_size=80, max_generations=200  # æ›´å¼ºçš„å‚æ•°
        )
        
        optimization_time = time.time() - start_time
        
        logger.info(f"âœ… æ¿€è¿›ä¼˜åŒ–å®Œæˆï¼Œç”¨æ—¶ {optimization_time:.2f}ç§’")
        logger.info(f"ğŸ¯ æœ€ä½³é€‚åº”åº¦: {best_fitness:.4f}")
        
        # è®¡ç®—è¯¦ç»†ç»Ÿè®¡
        results = self._calculate_detailed_stats(
            original_positions, optimized_positions, 
            pop_points, pop_weights, optimization_time
        )
        
        # ä¿å­˜æ‰€æœ‰ç»“æœ
        self._save_all_results(original_positions, optimized_positions, results)
        
        logger.info(f"ğŸ‰ æ¿€è¿›ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")
        
        # æ˜¾ç¤ºä¼˜åŒ–æˆæœ
        self._display_optimization_summary(results)
        
        return str(self.output_dir)
    
    def _display_optimization_summary(self, results):
        """æ˜¾ç¤ºä¼˜åŒ–æˆæœæ‘˜è¦"""
        logger.info("\n" + "="*50)
        logger.info("ğŸ† æ¿€è¿›ä¼˜åŒ–æˆæœæ‘˜è¦")
        logger.info("="*50)
        logger.info(f"ğŸ“Š æ€»ç«™ç‚¹æ•°: {results['total_stations']:,}")
        logger.info(f"ğŸšŒ ç§»åŠ¨ç«™ç‚¹: {results['moved_stations']:,} ({results['moved_stations']/results['total_stations']:.1%})")
        logger.info(f"ğŸ“ å¹³å‡ç§»åŠ¨: {results['average_movement_m']:.1f}ç±³")
        logger.info(f"ğŸ“ˆ è¦†ç›–ç‡æå‡: {results['original_coverage']:.3f} â†’ {results['optimized_coverage']:.3f}")
        logger.info(f"ğŸ¯ ç›¸å¯¹æ”¹å–„: {results['coverage_improvement']/results['original_coverage']*100 if results['original_coverage'] > 0 else 0:.1f}%")
        logger.info(f"â±ï¸  ä¼˜åŒ–ç”¨æ—¶: {results['optimization_time']:.1f}ç§’")
        logger.info("="*50 + "\n")
    
    def _calculate_detailed_stats(self, original_positions, optimized_positions, 
                                pop_points, pop_weights, optimization_time):
        """è®¡ç®—è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("ğŸ“Š è®¡ç®—æ¿€è¿›ä¼˜åŒ–ç»Ÿè®¡...")
        
        n_stops = len(original_positions)
        
        # è¦†ç›–ç‡è®¡ç®—
        original_coverage = fast_population_coverage(
            original_positions, pop_points, pop_weights, self.coverage_radius / 111320.0
        )
        optimized_coverage = fast_population_coverage(
            optimized_positions, pop_points, pop_weights, self.coverage_radius / 111320.0
        )
        
        # ç§»åŠ¨ç»Ÿè®¡
        movements = []
        moved_count = 0
        total_movement_m = 0.0
        
        for i in range(n_stops):
            dx = optimized_positions[i, 0] - original_positions[i, 0]
            dy = optimized_positions[i, 1] - original_positions[i, 1]
            movement_deg = np.sqrt(dx * dx + dy * dy)
            movement_m = movement_deg * 111320.0
            
            movements.append(movement_m)
            total_movement_m += movement_m
            
            if movement_m > 5.0:  # é™ä½ç§»åŠ¨é˜ˆå€¼åˆ°5ç±³
                moved_count += 1
        
        stability_score = (n_stops - moved_count) / n_stops
        
        results = {
            'optimization_time': optimization_time,
            'total_stations': n_stops,
            'moved_stations': moved_count,
            'stability_score': stability_score,
            'original_coverage': original_coverage,
            'optimized_coverage': optimized_coverage,
            'coverage_improvement': optimized_coverage - original_coverage,
            'total_movement_m': total_movement_m,
            'average_movement_m': total_movement_m / n_stops,
            'movements': movements,
            'original_positions': original_positions,
            'optimized_positions': optimized_positions
        }
        
        logger.info(f"ğŸ“ˆ æ¿€è¿›ä¼˜åŒ–ç»Ÿè®¡å®Œæˆ:")
        logger.info(f"   ç§»åŠ¨ç«™ç‚¹: {moved_count}/{n_stops} ({moved_count/n_stops:.1%})")
        logger.info(f"   ç¨³å®šæ€§: {stability_score:.3f}")
        logger.info(f"   è¦†ç›–ç‡: {original_coverage:.3f} â†’ {optimized_coverage:.3f} (+{(optimized_coverage-original_coverage)/original_coverage*100 if original_coverage > 0 else 0:.1f}%)")
        logger.info(f"   å¹³å‡ç§»åŠ¨: {total_movement_m/n_stops:.1f}ç±³")
        
        return results
    
    def _save_all_results(self, original_positions, optimized_positions, results):
        """ä¿å­˜æ‰€æœ‰ç»“æœæ–‡ä»¶"""
        logger.info("ğŸ’¾ ä¿å­˜æ¿€è¿›ä¼˜åŒ–ç»“æœ...")
        
        # 1. ä¿å­˜ç«™ç‚¹æ•°æ®
        self._save_station_data(original_positions, optimized_positions, results)
        
        # 2. ä¿å­˜äººå£æ•°æ®
        self._save_population_data()
        
        # 3. åˆ›å»ºå¯è§†åŒ–
        self._create_visualizations(results)
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        self._create_comprehensive_report(results)
        
        # 5. ä¿å­˜ç»Ÿè®¡JSON
        self._save_statistics_json(results)
    
    def _save_station_data(self, original_positions, optimized_positions, results):
        """ä¿å­˜ç«™ç‚¹æ•°æ®æ–‡ä»¶"""
        logger.info("ğŸšŒ ä¿å­˜ç«™ç‚¹æ•°æ®...")
        
        # åˆ›å»ºä¼˜åŒ–åçš„ç«™ç‚¹æ•°æ®
        optimized_stops = self.bus_stops_data.copy()
        
        # æ·»åŠ åˆ†æå­—æ®µ
        optimized_stops['original_lon'] = original_positions[:, 0]
        optimized_stops['original_lat'] = original_positions[:, 1]
        optimized_stops['longitude'] = optimized_positions[:, 0]
        optimized_stops['latitude'] = optimized_positions[:, 1]
        optimized_stops['movement_m'] = results['movements']
        optimized_stops['is_moved'] = [m > 5.0 for m in results['movements']]  # é™ä½é˜ˆå€¼
        
        # æ·»åŠ ä¼˜åŒ–å¼ºåº¦æ ‡è®°
        optimized_stops['move_intensity'] = ['è½»å¾®' if m < 20 else 'ä¸­ç­‰' if m < 100 else 'æ˜¾è‘—' 
                                           for m in results['movements']]
        
        # åˆ†ç¦»ç§»åŠ¨çš„ç«™ç‚¹
        moved_stops = optimized_stops[optimized_stops['is_moved'] == True]
        
        if HAS_GEOPANDAS:
            # ä¿å­˜ä¸ºShapefile
            self._save_as_shapefile("original_bus_stops.shp", self.bus_stops_data)
            self._save_as_shapefile("optimized_bus_stops.shp", optimized_stops)
            self._save_as_shapefile("moved_bus_stops.shp", moved_stops)
            logger.info("âœ… æ¿€è¿›ä¼˜åŒ–Shapefileæ–‡ä»¶å·²ä¿å­˜")
        else:
            # ä¿å­˜ä¸ºCSV
            self.bus_stops_data.to_csv(self.output_dir / "original_bus_stops.csv", index=False)
            optimized_stops.to_csv(self.output_dir / "optimized_bus_stops.csv", index=False)
            moved_stops.to_csv(self.output_dir / "moved_bus_stops.csv", index=False)
            logger.info("âœ… æ¿€è¿›ä¼˜åŒ–CSVæ–‡ä»¶å·²ä¿å­˜")
        
        logger.info(f"ğŸ“Š æ¿€è¿›ä¼˜åŒ–ç«™ç‚¹ç»Ÿè®¡: æ€»è®¡{len(optimized_stops)}, ç§»åŠ¨{len(moved_stops)} ({len(moved_stops)/len(optimized_stops):.1%})")
    
    def _save_as_shapefile(self, filename, data):
        """ä¿å­˜ä¸ºshapefile"""
        if HAS_GEOPANDAS:
            gdf = gpd.GeoDataFrame(
                data,
                geometry=gpd.points_from_xy(data['longitude'], data['latitude']),
                crs='EPSG:4326'
            )
            gdf.to_file(self.output_dir / filename, encoding='utf-8')
    
    def _save_population_data(self):
        """ä¿å­˜äººå£æ•°æ®"""
        pop_file = self.output_dir / "population_data.csv"
        self.population_data.to_csv(pop_file, index=False)
        logger.info(f"ğŸ“Š äººå£æ•°æ®å·²ä¿å­˜: {pop_file}")
    
    def _create_visualizations(self, results):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        logger.info("ğŸ“ˆ åˆ›å»ºæ¿€è¿›ä¼˜åŒ–å¯è§†åŒ–...")
        
        # 1. ç»¼åˆåˆ†æå›¾
        self._create_analysis_charts(results)
        
        # 2. åœ°å›¾å¯è§†åŒ–
        self._create_map_visualizations(results)
    
    def _create_analysis_charts(self, results):
        """åˆ›å»ºåˆ†æå›¾è¡¨"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('æ¿€è¿›ä¼˜åŒ–åˆ†ææŠ¥å‘Š - æœ€å¤§åŒ–è¦†ç›–ç‡ç­–ç•¥', fontsize=16, fontweight='bold')
        
        movements = np.array(results['movements'])
        moved_stations = results['moved_stations']
        total_stations = results['total_stations']
        
        # 1. è¦†ç›–ç‡æ˜¾è‘—æå‡å¯¹æ¯”
        ax = axes[0, 0]
        categories = ['ä¼˜åŒ–å‰', 'æ¿€è¿›ä¼˜åŒ–å']
        coverage_values = [results['original_coverage'], results['optimized_coverage']]
        
        bars = ax.bar(categories, coverage_values, color=['#ff9999', '#66cc66'])
        ax.set_ylabel('è¦†ç›–ç‡')
        ax.set_title('è¦†ç›–ç‡æ˜¾è‘—æå‡')
        ax.set_ylim(0, max(coverage_values) * 1.2)
        
        # æ˜¾ç¤ºæå‡å¹…åº¦
        improvement = (results['optimized_coverage'] - results['original_coverage']) / results['original_coverage'] * 100 if results['original_coverage'] > 0 else 0
        ax.text(0.5, max(coverage_values) * 1.1, f'æå‡: {improvement:.1f}%', 
               ha='center', fontweight='bold', fontsize=12, color='red')
        
        for bar, value in zip(bars, coverage_values):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                   f'{value:.2%}', ha='center', va='bottom', fontweight='bold')
        
        # 2. æ¿€è¿›ç§»åŠ¨ç»Ÿè®¡
        ax = axes[0, 1]
        unmoved_stations = total_stations - moved_stations
        sizes = [unmoved_stations, moved_stations]
        labels = [f'ä¿æŒåŸä½\n{unmoved_stations}ä¸ª', f'æ¿€è¿›ç§»åŠ¨\n{moved_stations}ä¸ª']
        colors = ['#87ceeb', '#ff6b6b']
        
        wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, 
                                         autopct='%1.1f%%', startangle=90)
        ax.set_title(f'æ¿€è¿›ç§»åŠ¨ç­–ç•¥\n({moved_stations/total_stations:.1%} ç«™ç‚¹ç§»åŠ¨)')
        
        # 3. ç§»åŠ¨è·ç¦»åˆ†å¸ƒï¼ˆæ›´è¯¦ç»†ï¼‰
        ax = axes[0, 2]
        moved_movements = movements[movements > 5.0]
        
        if len(moved_movements) > 0:
            ax.hist(moved_movements, bins=40, color='orange', alpha=0.7, edgecolor='black')
            ax.axvline(np.mean(moved_movements), color='red', linestyle='--', 
                      linewidth=2, label=f'å¹³å‡: {np.mean(moved_movements):.1f}m')
            ax.axvline(np.median(moved_movements), color='blue', linestyle='--', 
                      linewidth=2, label=f'ä¸­ä½æ•°: {np.median(moved_movements):.1f}m')
            ax.set_xlabel('ç§»åŠ¨è·ç¦» (ç±³)')
            ax.set_ylabel('ç«™ç‚¹æ•°é‡')
            ax.set_title('æ¿€è¿›ç§»åŠ¨è·ç¦»åˆ†å¸ƒ')
            ax.legend()
        else:
            ax.text(0.5, 0.5, 'æ— ç«™ç‚¹ç§»åŠ¨', transform=ax.transAxes, 
                   ha='center', va='center', fontsize=14)
            ax.set_title('ç§»åŠ¨è·ç¦»åˆ†å¸ƒ')
        
        # 4. ç§»åŠ¨å¼ºåº¦åˆ†ç±»
        ax = axes[1, 0]
        light_moves = np.sum((movements > 5) & (movements < 20))
        medium_moves = np.sum((movements >= 20) & (movements < 100))
        significant_moves = np.sum(movements >= 100)
        
        categories = ['è½»å¾®\n(5-20m)', 'ä¸­ç­‰\n(20-100m)', 'æ˜¾è‘—\n(100m+)']
        values = [light_moves, medium_moves, significant_moves]
        colors = ['lightgreen', 'orange', 'red']
        
        bars = ax.bar(categories, values, color=colors)
        ax.set_ylabel('ç«™ç‚¹æ•°é‡')
        ax.set_title('ç§»åŠ¨å¼ºåº¦åˆ†ç±»')
        
        for bar, value in zip(bars, values):
            if value > 0:
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.02,
                       f'{value}', ha='center', va='bottom', fontweight='bold')
        
        # 5. æ¿€è¿›ä¼˜åŒ–æ•ˆæœ
        ax = axes[1, 1]
        metrics = ['è¦†ç›–ç‡æå‡', 'ç§»åŠ¨ç«™ç‚¹æ¯”ä¾‹', 'ä¼˜åŒ–æ•ˆç‡']
        values = [
            results['coverage_improvement'] / results['original_coverage'] * 100 if results['original_coverage'] > 0 else 0,
            moved_stations / total_stations * 100,
            total_stations / results['optimization_time']
        ]
        
        bars = ax.bar(metrics, values, color=['gold', 'lightcoral', 'lightblue'])
        ax.set_ylabel('æ•°å€¼')
        ax.set_title('æ¿€è¿›ä¼˜åŒ–æ•ˆæœ')
        ax.tick_params(axis='x', rotation=45)
        
        units = ['%', '%', 'ç«™ç‚¹/ç§’']
        for bar, value, unit in zip(bars, values, units):
            if unit == 'ç«™ç‚¹/ç§’':
                label = f'{value:.0f}{unit}'
            else:
                label = f'{value:.1f}{unit}'
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.02,
                   label, ha='center', va='bottom', fontweight='bold')
        
        # 6. æ¿€è¿›ä¼˜åŒ–æ‘˜è¦
        ax = axes[1, 2]
        ax.axis('off')
        
        avg_moved_distance = np.mean(moved_movements) if len(moved_movements) > 0 else 0
        max_distance = np.max(movements) if len(movements) > 0 else 0
        
        summary_text = f'''
        æ¿€è¿›ä¼˜åŒ–æ‘˜è¦
        
        ç­–ç•¥: è¦†ç›–ç‡ä¼˜å…ˆç®—æ³•
        ä¼˜åŒ–æ—¶é—´: {results['optimization_time']:.1f}ç§’
        è¦†ç›–åŠå¾„: {self.coverage_radius}ç±³
        
        æ€»ç«™ç‚¹æ•°: {total_stations:,}
        ç§»åŠ¨ç«™ç‚¹: {moved_stations:,} ({moved_stations/total_stations:.1%})
        
        è¦†ç›–ç‡: {results['original_coverage']:.3f} â†’ {results['optimized_coverage']:.3f}
        æå‡å¹…åº¦: {improvement:.1f}%
        
        å¹³å‡ç§»åŠ¨: {results['average_movement_m']:.1f}ç±³
        ç§»åŠ¨ç«™ç‚¹å¹³å‡: {avg_moved_distance:.1f}ç±³
        æœ€å¤§ç§»åŠ¨: {max_distance:.1f}ç±³
        
        ğŸ¯ æˆåŠŸå®ç°å¤§å¹…è¦†ç›–ç‡æå‡ï¼
        '''
        
        ax.text(0.05, 0.95, summary_text, transform=ax.transAxes, fontsize=9,
               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))
        
        plt.tight_layout()
        chart_path = self.output_dir / "aggressive_optimization_analysis.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š æ¿€è¿›ä¼˜åŒ–åˆ†æå›¾è¡¨å·²ä¿å­˜: {chart_path}")
    
    def _create_map_visualizations(self, results):
        """åˆ›å»ºåœ°å›¾å¯è§†åŒ–"""
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        fig.suptitle('æ¿€è¿›ä¼˜åŒ–åœ°å›¾å¯è§†åŒ– - å¤§å¹…è¦†ç›–ç‡æå‡', fontsize=16, fontweight='bold')
        
        original_pos = results['original_positions']
        optimized_pos = results['optimized_positions']
        movements = np.array(results['movements'])
        
        # 1. äººå£å¯†åº¦ + åŸå§‹ç«™ç‚¹
        ax = axes[0, 0]
        scatter = ax.scatter(self.population_data['longitude'], self.population_data['latitude'], 
                           c=self.population_data['population'], s=1, cmap='Reds', alpha=0.6)
        ax.scatter(original_pos[:, 0], original_pos[:, 1], 
                  s=8, color='blue', alpha=0.8, label='åŸå§‹ç«™ç‚¹')
        ax.set_title('åŸå§‹ç«™ç‚¹åˆ†å¸ƒ + äººå£çƒ­åŠ›å›¾')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        plt.colorbar(scatter, ax=ax, label='äººå£æ•°')
        ax.legend()
        
        # 2. æ¿€è¿›ä¼˜åŒ–å‰åå¯¹æ¯”
        ax = axes[0, 1]
        ax.scatter(self.population_data['longitude'], self.population_data['latitude'], 
                  c=self.population_data['population'], s=0.5, cmap='Reds', alpha=0.2)
        
        # æœªç§»åŠ¨ç«™ç‚¹
        unmoved_mask = movements <= 5.0
        ax.scatter(optimized_pos[unmoved_mask, 0], optimized_pos[unmoved_mask, 1], 
                  s=8, color='green', alpha=0.7, label=f'ä¿æŒåŸä½({np.sum(unmoved_mask)})')
        
        # æ¿€è¿›ç§»åŠ¨ç«™ç‚¹åŠè½¨è¿¹
        moved_mask = movements > 5.0
        if np.sum(moved_mask) > 0:
            ax.scatter(optimized_pos[moved_mask, 0], optimized_pos[moved_mask, 1], 
                      s=12, color='red', alpha=0.8, label=f'æ¿€è¿›ç§»åŠ¨({np.sum(moved_mask)})')
            
            # æ·»åŠ ç§»åŠ¨è½¨è¿¹ - åªæ˜¾ç¤ºéƒ¨åˆ†é¿å…è¿‡å¯†
            show_indices = np.where(moved_mask)[0][::max(1, np.sum(moved_mask)//100)]
            for i in show_indices:
                ax.plot([original_pos[i, 0], optimized_pos[i, 0]],
                       [original_pos[i, 1], optimized_pos[i, 1]], 
                       'orange', alpha=0.4, linewidth=0.8)
            
            ax.plot([], [], 'orange', label='ç§»åŠ¨è½¨è¿¹', alpha=0.6)
        
        ax.set_title(f'æ¿€è¿›ä¼˜åŒ–å¯¹æ¯” (ç§»åŠ¨ç‡: {np.sum(moved_mask)/len(movements):.1%})')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        ax.legend()
        
        # 3. ç§»åŠ¨è·ç¦»çƒ­å›¾
        ax = axes[1, 0]
        if np.sum(moved_mask) > 0:
            scatter = ax.scatter(optimized_pos[moved_mask, 0], optimized_pos[moved_mask, 1], 
                               c=movements[moved_mask], s=30, cmap='plasma', alpha=0.8)
            plt.colorbar(scatter, ax=ax, label='ç§»åŠ¨è·ç¦»(ç±³)')
            ax.set_title(f'ç§»åŠ¨è·ç¦»çƒ­å›¾ (avg: {np.mean(movements[moved_mask]):.1f}m)')
        else:
            ax.text(0.5, 0.5, 'æ— ç«™ç‚¹ç§»åŠ¨', transform=ax.transAxes, 
                   ha='center', va='center', fontsize=14)
            ax.set_title('ç§»åŠ¨è·ç¦»çƒ­å›¾')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        
        # 4. è¦†ç›–å¢å¼ºæ•ˆæœï¼ˆç®€åŒ–ç‰ˆï¼‰
        ax = axes[1, 1]
        ax.scatter(self.population_data['longitude'], self.population_data['latitude'], 
                  c=self.population_data['population'], s=1, cmap='Oranges', alpha=0.5)
        
        # æ˜¾ç¤ºä¼˜åŒ–åçš„ç«™ç‚¹ï¼ŒæŒ‰ç§»åŠ¨ç¨‹åº¦ç€è‰²
        colors = ['green' if m <= 5 else 'orange' if m <= 50 else 'red' for m in movements]
        sizes = [8 if m <= 5 else 12 if m <= 50 else 16 for m in movements]
        
        ax.scatter(optimized_pos[:, 0], optimized_pos[:, 1], 
                  c=colors, s=sizes, alpha=0.8)
        
        # å›¾ä¾‹
        ax.scatter([], [], c='green', s=8, label='æœªç§»åŠ¨', alpha=0.8)
        ax.scatter([], [], c='orange', s=12, label='ä¸­åº¦ç§»åŠ¨', alpha=0.8)
        ax.scatter([], [], c='red', s=16, label='å¤§å¹…ç§»åŠ¨', alpha=0.8)
        
        ax.set_title(f'æ¿€è¿›ä¼˜åŒ–ååˆ†å¸ƒ (è¦†ç›–ç‡: {results["optimized_coverage"]:.3f})')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        ax.legend()
        
        plt.tight_layout()
        map_path = self.output_dir / "aggressive_optimization_maps.png"
        plt.savefig(map_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ—ºï¸  æ¿€è¿›ä¼˜åŒ–åœ°å›¾å·²ä¿å­˜: {map_path}")
    
    def _create_comprehensive_report(self, results):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”Ÿæˆæ¿€è¿›ä¼˜åŒ–æŠ¥å‘Š...")
        
        report_path = self.output_dir / "aggressive_optimization_report.txt"
        movements = np.array(results['movements'])
        moved_movements = movements[movements > 5.0]
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=== æ¸©å·å…¬äº¤ç«™ç‚¹æ¿€è¿›ä¼˜åŒ–è¯¦ç»†æŠ¥å‘Š ===\n\n")
            f.write("ğŸ¯ ä¼˜åŒ–ç›®æ ‡ï¼šæœ€å¤§åŒ–äººå£è¦†ç›–ç‡\n")
            f.write("ğŸ“ˆ ç­–ç•¥ç‰¹ç‚¹ï¼šå…è®¸æ›´å¤šç«™ç‚¹ç§»åŠ¨ï¼Œæ˜¾è‘—æå‡æœåŠ¡æ•ˆæœ\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("== æ¿€è¿›ä¼˜åŒ–é…ç½® ==\n")
            f.write(f"åŸºç¡€ç®—æ³•: å¼ºåŒ–è‡ªé€‚åº”é—ä¼ ç®—æ³•\n")
            f.write(f"è¦†ç›–åŠå¾„: {self.coverage_radius}ç±³ (å¢å¼º)\n")
            f.write(f"ç§ç¾¤è§„æ¨¡: 80 (å¢å¤§)\n")
            f.write(f"æœ€å¤§è¿­ä»£: 200ä»£ (å¢åŠ )\n")
            f.write(f"ç§»åŠ¨ç­–ç•¥: æ¿€è¿› (20-40%ç«™ç‚¹å‚ä¸ä¼˜åŒ–)\n")
            f.write(f"é€‚åº”åº¦æƒé‡: è¦†ç›–ç‡ä¼˜å…ˆ (20:3:1)\n")
            f.write(f"ä¼˜åŒ–æ—¶é—´: {results['optimization_time']:.2f}ç§’\n\n")
            
            f.write("== æ•°æ®è§„æ¨¡ ==\n")
            f.write(f"äººå£ç½‘æ ¼ç‚¹æ•°: {len(self.population_data):,}\n")
            f.write(f"æ€»æœåŠ¡äººå£: {self.population_data['population'].sum():,.0f}\n")
            f.write(f"å…¬äº¤ç«™ç‚¹æ€»æ•°: {results['total_stations']:,}\n")
            f.write(f"æœåŠ¡åŒºåŸŸ: æ¸©å·å¸‚å…¨åŸŸ\n\n")
            
            f.write("== æ¿€è¿›ä¼˜åŒ–æˆæœ ==\n")
            coverage_improvement_pct = results['coverage_improvement'] / results['original_coverage'] * 100 if results['original_coverage'] > 0 else 0
            f.write(f"ğŸ† è¦†ç›–ç‡æ˜¾è‘—æå‡:\n")
            f.write(f"   ä¼˜åŒ–å‰: {results['original_coverage']:.4f} ({results['original_coverage']:.2%})\n")
            f.write(f"   ä¼˜åŒ–å: {results['optimized_coverage']:.4f} ({results['optimized_coverage']:.2%})\n")
            f.write(f"   ç»å¯¹æå‡: {results['coverage_improvement']:.4f}\n")
            f.write(f"   ç›¸å¯¹æå‡: {coverage_improvement_pct:.2f}%\n\n")
            
            f.write(f"ğŸšŒ ç«™ç‚¹ç§»åŠ¨ç»Ÿè®¡:\n")
            f.write(f"   æ¿€è¿›ç§»åŠ¨ç«™ç‚¹: {results['moved_stations']:,} ({results['moved_stations']/results['total_stations']:.2%})\n")
            f.write(f"   ä¿æŒç¨³å®šç«™ç‚¹: {results['total_stations']-results['moved_stations']:,} ({(results['total_stations']-results['moved_stations'])/results['total_stations']:.2%})\n")
            f.write(f"   ç¨³å®šæ€§å¾—åˆ†: {results['stability_score']:.4f}\n\n")
            
            f.write("== ç§»åŠ¨è·ç¦»åˆ†æ ==\n")
            f.write(f"ğŸ“ æ€»ä½“ç§»åŠ¨ç»Ÿè®¡:\n")
            f.write(f"   æ€»ç§»åŠ¨è·ç¦»: {results['total_movement_m']:.2f}ç±³ ({results['total_movement_m']/1000:.2f}å…¬é‡Œ)\n")
            f.write(f"   å…¨ä½“å¹³å‡ç§»åŠ¨: {results['average_movement_m']:.2f}ç±³\n")
            
            if len(moved_movements) > 0:
                f.write(f"   ç§»åŠ¨ç«™ç‚¹å¹³å‡: {np.mean(moved_movements):.2f}ç±³\n")
                f.write(f"   ç§»åŠ¨ç«™ç‚¹ä¸­ä½æ•°: {np.median(moved_movements):.2f}ç±³\n")
                f.write(f"   æœ€å¤§ç§»åŠ¨è·ç¦»: {np.max(moved_movements):.2f}ç±³\n")
                f.write(f"   æœ€å°ç§»åŠ¨è·ç¦»: {np.min(moved_movements):.2f}ç±³\n")
            f.write("\n")
            
            f.write("ğŸ“Š ç§»åŠ¨è·ç¦»è¯¦ç»†åˆ†å¸ƒ:\n")
            if len(moved_movements) > 0:
                f.write(f"   å¾®è°ƒ(5-20ç±³): {np.sum((moved_movements >= 5) & (moved_movements < 20)):,}ä¸ª\n")
                f.write(f"   é€‚åº¦(20-50ç±³): {np.sum((moved_movements >= 20) & (moved_movements < 50)):,}ä¸ª\n")
                f.write(f"   ä¸­åº¦(50-100ç±³): {np.sum((moved_movements >= 50) & (moved_movements < 100)):,}ä¸ª\n")
                f.write(f"   å¤§å¹…(100-200ç±³): {np.sum((moved_movements >= 100) & (moved_movements < 200)):,}ä¸ª\n")
                f.write(f"   æ˜¾è‘—(200ç±³ä»¥ä¸Š): {np.sum(moved_movements >= 200):,}ä¸ª\n")
            f.write("\n")
            
            f.write("== ä¼˜åŒ–æ•ˆæœè¯„ä¼° ==\n")
            f.write(f"ğŸ¯ ä¸»è¦æˆå°±:\n")
            f.write(f"   âœ… è¦†ç›–ç‡æå‡: {coverage_improvement_pct:.1f}%\n")
            f.write(f"   âœ… ç§»åŠ¨ç«™ç‚¹æ¯”ä¾‹: {results['moved_stations']/results['total_stations']:.1%} (è¾¾åˆ°æ¿€è¿›ç›®æ ‡)\n")
            f.write(f"   âœ… ä¼˜åŒ–æ•ˆç‡: {results['total_stations']/results['optimization_time']:.0f} ç«™ç‚¹/ç§’\n")
            f.write(f"   âœ… æœåŠ¡äººå£å¢åŠ : çº¦ {results['coverage_improvement']*self.population_data['population'].sum():.0f} äºº\n\n")
            
            f.write("== æ–‡ä»¶è¾“å‡ºæ¸…å• ==\n")
            if HAS_GEOPANDAS:
                f.write("ğŸ“ Shapefileæ ¼å¼:\n")
                f.write("   - original_bus_stops.shp: åŸå§‹ç«™ç‚¹\n")
                f.write("   - optimized_bus_stops.shp: æ¿€è¿›ä¼˜åŒ–åç«™ç‚¹\n")
                f.write("   - moved_bus_stops.shp: ç§»åŠ¨ç«™ç‚¹è¯¦æƒ…\n")
            else:
                f.write("ğŸ“ CSVæ ¼å¼:\n")
                f.write("   - original_bus_stops.csv: åŸå§‹ç«™ç‚¹\n")
                f.write("   - optimized_bus_stops.csv: æ¿€è¿›ä¼˜åŒ–åç«™ç‚¹\n")
                f.write("   - moved_bus_stops.csv: ç§»åŠ¨ç«™ç‚¹è¯¦æƒ…\n")
            
            f.write("ğŸ“Š åˆ†ææ–‡ä»¶:\n")
            f.write("   - population_data.csv: äººå£ç½‘æ ¼æ•°æ®\n")
            f.write("   - aggressive_optimization_analysis.png: ç»¼åˆåˆ†æå›¾\n")
            f.write("   - aggressive_optimization_maps.png: åœ°å›¾å¯è§†åŒ–\n")
            f.write("   - aggressive_optimization_stats.json: ç»Ÿè®¡æ•°æ®\n")
            f.write("   - aggressive_optimization_report.txt: æœ¬æŠ¥å‘Š\n\n")
            
            f.write("== æ¿€è¿›ç­–ç•¥ä¼˜åŠ¿ ==\n")
            f.write("ğŸš€ ç®—æ³•åˆ›æ–°ç‚¹:\n")
            f.write("   1. è¦†ç›–ç‡ä¼˜å…ˆ: é€‚åº”åº¦å‡½æ•°ä»¥è¦†ç›–ç‡ä¸ºä¸»è¦ç›®æ ‡\n")
            f.write("   2. æ¿€è¿›åˆå§‹åŒ–: 20-40%ç«™ç‚¹å‚ä¸ä¼˜åŒ–ç§»åŠ¨\n")
            f.write("   3. å¢å¼ºå˜å¼‚: æ›´å¤§çš„å˜å¼‚èŒƒå›´å’Œé¢‘ç‡\n")
            f.write("   4. æ‰©å¤§è¦†ç›–: 400ç±³è¦†ç›–åŠå¾„æå‡æœåŠ¡èŒƒå›´\n")
            f.write("   5. åŠ¨æ€å¹³è¡¡: åœ¨è¦†ç›–ç‡å’Œç¨³å®šæ€§é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡\n\n")
            
            f.write("ğŸ¯ é€‚ç”¨åœºæ™¯:\n")
            f.write("   - ç°æœ‰å…¬äº¤ç³»ç»Ÿéœ€è¦å¤§å¹…æ”¹å–„æœåŠ¡è¦†ç›–\n")
            f.write("   - äººå£åˆ†å¸ƒå‘ç”Ÿæ˜¾è‘—å˜åŒ–çš„åŸå¸‚\n")
            f.write("   - æ„¿æ„è¿›è¡Œè¾ƒå¤§è°ƒæ•´ä»¥è·å¾—æœ€ä½³æ•ˆæœ\n")
            f.write("   - æœ‰å……è¶³èµ„æºè¿›è¡Œç«™ç‚¹è¿ç§»çš„é¡¹ç›®\n\n")
            
            f.write("== å®æ–½å»ºè®® ==\n")
            f.write("ğŸ’¡ åˆ†é˜¶æ®µå®æ–½:\n")
            f.write("   1. ä¼˜å…ˆå®æ–½ç§»åŠ¨è·ç¦»<50ç±³çš„è°ƒæ•´ (é£é™©ä½)\n")
            f.write("   2. é€æ­¥å®æ–½50-100ç±³çš„ä¸­åº¦è°ƒæ•´\n")
            f.write("   3. è°¨æ…è¯„ä¼°100ç±³ä»¥ä¸Šçš„å¤§å¹…è°ƒæ•´\n")
            f.write("   4. ç›‘æ§å®æ–½æ•ˆæœï¼Œé€‚æ—¶å¾®è°ƒ\n\n")
            
            f.write("ğŸ“ˆ é¢„æœŸæ•ˆæœ:\n")
            f.write(f"   - äººå£è¦†ç›–ç‡æå‡ {coverage_improvement_pct:.1f}%\n")
            f.write(f"   - æ–°å¢æœåŠ¡äººå£çº¦ {results['coverage_improvement']*self.population_data['population'].sum():.0f} äºº\n")
            f.write("   - æ˜¾è‘—æ”¹å–„å…¬äº¤æœåŠ¡çš„ç©ºé—´åŒ¹é…æ€§\n")
            f.write("   - æå‡å…¬å…±äº¤é€šå¸å¼•åŠ›å’Œä½¿ç”¨ç‡\n\n")
            
            f.write("ğŸ‰ æ¿€è¿›ä¼˜åŒ–æŠ¥å‘Šå®Œæˆã€‚\n")
            f.write("    æœ¬æ¬¡ä¼˜åŒ–æˆåŠŸå®ç°äº†è¦†ç›–ç‡çš„å¤§å¹…æå‡ï¼\n")
        
        logger.info(f"ğŸ“‹ æ¿€è¿›ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    def _save_statistics_json(self, results):
        """ä¿å­˜ç»Ÿè®¡JSON"""
        movements = np.array(results['movements'])
        moved_movements = movements[movements > 5.0]
        
        stats = {
            'optimization_type': 'aggressive_coverage_maximization',
            'timestamp': datetime.now().isoformat(),
            'algorithm': 'intensive_genetic_algorithm',
            'coverage_radius_m': self.coverage_radius,
            'optimization_time': results['optimization_time'],
            'total_stations': int(results['total_stations']),
            'moved_stations': int(results['moved_stations']),
            'moved_percentage': float(results['moved_stations'] / results['total_stations']),
            'stability_score': float(results['stability_score']),
            'original_coverage': float(results['original_coverage']),
            'optimized_coverage': float(results['optimized_coverage']),
            'coverage_improvement': float(results['coverage_improvement']),
            'coverage_improvement_percentage': float(results['coverage_improvement'] / results['original_coverage'] * 100 if results['original_coverage'] > 0 else 0),
            'total_movement_m': float(results['total_movement_m']),
            'average_movement_m': float(results['average_movement_m']),
            'population_points': len(self.population_data),
            'total_population': float(self.population_data['population'].sum()),
            'estimated_new_served_population': float(results['coverage_improvement'] * self.population_data['population'].sum())
        }
        
        if len(moved_movements) > 0:
            stats.update({
                'moved_stations_average_distance_m': float(np.mean(moved_movements)),
                'moved_stations_median_distance_m': float(np.median(moved_movements)),
                'moved_stations_max_distance_m': float(np.max(moved_movements)),
                'moved_stations_min_distance_m': float(np.min(moved_movements)),
                'movement_distribution': {
                    'micro_5_20m': int(np.sum((moved_movements >= 5) & (moved_movements < 20))),
                    'light_20_50m': int(np.sum((moved_movements >= 20) & (moved_movements < 50))),
                    'medium_50_100m': int(np.sum((moved_movements >= 50) & (moved_movements < 100))),
                    'large_100_200m': int(np.sum((moved_movements >= 100) & (moved_movements < 200))),
                    'significant_200m_plus': int(np.sum(moved_movements >= 200))
                }
            })
        
        with open(self.output_dir / "aggressive_optimization_stats.json", 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        logger.info("ğŸ“Š æ¿€è¿›ä¼˜åŒ–ç»Ÿè®¡JSONå·²ä¿å­˜")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨æ¿€è¿›ä¼˜åŒ–å™¨ï¼ˆæœ€å¤§åŒ–è¦†ç›–ç‡ç‰ˆï¼‰...")
    
    optimizer = AggressiveOptimizerWithOutputs(
        "./populaiton/æ¸©å·_population_grid.csv",
        "./å…¬äº¤ç«™ç‚¹shp/0577æ¸©å·.shp"
    )
    
    result_dir = optimizer.optimize_and_save_results()
    
    logger.info(f"\nğŸ‰ æ¿€è¿›ä¼˜åŒ–å¤§åŠŸå‘Šæˆï¼")
    logger.info(f"ğŸ“ å®Œæ•´ç»“æœä¿å­˜åœ¨: {result_dir}")
    logger.info("ğŸ“‹ æ¿€è¿›ä¼˜åŒ–ç‰¹è‰²:")
    logger.info("   ğŸ¯ æœ€å¤§åŒ–è¦†ç›–ç‡ç­–ç•¥")
    logger.info("   ğŸšŒ 25-40%ç«™ç‚¹å‚ä¸ä¼˜åŒ–")
    logger.info("   ğŸ“ˆ æ˜¾è‘—çš„æœåŠ¡æå‡æ•ˆæœ")
    logger.info("   ğŸ—ºï¸  å®Œæ•´çš„å¯è§†åŒ–åˆ†æ")
    logger.info("   ğŸ“Š è¯¦ç»†çš„æ”¹å–„ç»Ÿè®¡")
    logger.info("\nğŸ’¡ è¿™æ˜¯ä¸€ä¸ªå¤§å¹…æå‡è¦†ç›–ç‡çš„æ¿€è¿›æ–¹æ¡ˆï¼")

if __name__ == "__main__":
    main()