"""
å…¨è§„æ¨¡ä¼˜åŒ–æµ‹è¯•è„šæœ¬
æä¾›ä¸åŒè§„æ¨¡çš„æµ‹è¯•é€‰é¡¹ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œ
"""

import numpy as np
import pandas as pd
import logging
import time
import psutil
import multiprocessing as mp
from pathlib import Path
import argparse

from full_scale_fixed import QuickFullScaleOptimizer

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å…¨å±€å·¥ä½œå‡½æ•°ï¼Œé¿å…pickleé—®é¢˜
def simple_test_worker(x):
    """ç®€å•æµ‹è¯•å·¥ä½œå‡½æ•°"""
    return x * x

class FullScaleTestManager:
    """å…¨è§„æ¨¡ä¼˜åŒ–æµ‹è¯•ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ç®¡ç†å™¨"""
        self.system_info = self._get_system_info()
        self._display_system_info()
    
    def _get_system_info(self) -> dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        memory = psutil.virtual_memory()
        return {
            'cpu_count': mp.cpu_count(),
            'memory_total_gb': memory.total / (1024**3),
            'memory_available_gb': memory.available / (1024**3),
            'memory_percent': memory.percent
        }
    
    def _display_system_info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        info = self.system_info
        logger.info(f"ğŸ–¥ï¸  ç³»ç»Ÿé…ç½®æ£€æŸ¥:")
        logger.info(f"   CPUæ ¸å¿ƒ: {info['cpu_count']}")
        logger.info(f"   å†…å­˜æ€»é‡: {info['memory_total_gb']:.1f}GB")
        logger.info(f"   å¯ç”¨å†…å­˜: {info['memory_available_gb']:.1f}GB ({100-info['memory_percent']:.1f}%)")
        
        # ç»™å‡ºå»ºè®®
        if info['memory_available_gb'] < 4:
            logger.warning("âš ï¸  å¯ç”¨å†…å­˜ä¸è¶³4GBï¼Œå»ºè®®ä½¿ç”¨å°è§„æ¨¡æµ‹è¯•æ¨¡å¼")
        elif info['memory_available_gb'] < 8:
            logger.info("ğŸ’¡ å¯ç”¨å†…å­˜é€‚ä¸­ï¼Œå»ºè®®ä½¿ç”¨ä¸­è§„æ¨¡æµ‹è¯•æ¨¡å¼")
        else:
            logger.info("âœ… å†…å­˜å……è¶³ï¼Œå¯ä»¥è¿è¡Œå…¨è§„æ¨¡ä¼˜åŒ–")
    
    def quick_test(self) -> dict:
        """å¿«é€Ÿæµ‹è¯•ï¼šéªŒè¯ç³»ç»ŸåŠŸèƒ½"""
        logger.info("ğŸš€ === å¿«é€ŸåŠŸèƒ½æµ‹è¯• ===")
        
        try:
            from data_preprocessing import DataProcessor
            
            # å¿«é€Ÿæ•°æ®åŠ è½½æµ‹è¯•
            logger.info("ğŸ“Š æµ‹è¯•æ•°æ®åŠ è½½...")
            processor = DataProcessor(
                "./populaiton/æ¸©å·_population_grid.csv",
                "./å…¬äº¤ç«™ç‚¹shp/0577æ¸©å·.shp"
            )
            pop_data, stop_data, _ = processor.get_processed_data()
            
            logger.info(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(pop_data)}äººå£ç‚¹, {len(stop_data)}ç«™ç‚¹")
            
            # å†…å­˜ä½¿ç”¨æµ‹è¯•
            memory_usage = psutil.virtual_memory().percent
            logger.info(f"ğŸ’¾ å†…å­˜ä½¿ç”¨ç‡: {memory_usage:.1f}%")
            
            # å¤šè¿›ç¨‹æµ‹è¯•
            logger.info("ğŸ”„ æµ‹è¯•å¤šè¿›ç¨‹ç¯å¢ƒ...")
            
            with mp.Pool(processes=min(2, mp.cpu_count())) as pool:
                results = pool.map(simple_test_worker, range(10))
            
            logger.info("âœ… å¤šè¿›ç¨‹æµ‹è¯•æˆåŠŸ")
            
            return {
                'status': 'success',
                'data_size': {'population': len(pop_data), 'stops': len(stop_data)},
                'memory_usage': memory_usage,
                'multiprocessing_ok': True
            }
            
        except Exception as e:
            logger.error(f"âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    def small_scale_test(self) -> dict:
        """å°è§„æ¨¡æµ‹è¯•ï¼šå¤„ç†éƒ¨åˆ†æ•°æ®"""
        logger.info("ğŸ¯ === å°è§„æ¨¡ä¼˜åŒ–æµ‹è¯• ===")
        
        try:
            # åˆ›å»ºé™åˆ¶ç‰ˆæœ¬çš„ä¼˜åŒ–å™¨
            optimizer = QuickFullScaleOptimizer(
                "./populaiton/æ¸©å·_population_grid.csv",
                "./å…¬äº¤ç«™ç‚¹shp/0577æ¸©å·.shp"
            )
            
            # é™åˆ¶å¤„ç†è§„æ¨¡
            original_blocks = optimizer.spatial_blocks
            optimizer.spatial_blocks = original_blocks[:min(4, len(original_blocks))]  # æœ€å¤š4ä¸ªåŒºåŸŸ
            optimizer.n_processes = min(2, mp.cpu_count())  # æœ€å¤š2ä¸ªè¿›ç¨‹
            
            logger.info(f"ğŸ“¦ é™åˆ¶å¤„ç†è§„æ¨¡: {len(optimizer.spatial_blocks)} ä¸ªåŒºåŸŸ")
            
            # è¿è¡Œä¼˜åŒ–
            start_time = time.time()
            result = optimizer.optimize_full_scale()
            test_time = time.time() - start_time
            
            logger.info(f"âœ… å°è§„æ¨¡æµ‹è¯•å®Œæˆï¼Œç”¨æ—¶ {test_time:.1f}ç§’")
            
            # é¢„ä¼°å…¨è§„æ¨¡æ—¶é—´
            total_blocks = len(original_blocks)
            estimated_full_time = test_time * (total_blocks / len(optimizer.spatial_blocks)) / optimizer.n_processes
            
            logger.info(f"â±ï¸  é¢„ä¼°å…¨è§„æ¨¡æ—¶é—´: {estimated_full_time:.1f}ç§’ ({estimated_full_time/60:.1f}åˆ†é’Ÿ)")
            
            return {
                'status': 'success',
                'test_time': test_time,
                'estimated_full_time': estimated_full_time,
                'blocks_tested': len(optimizer.spatial_blocks),
                'total_blocks': total_blocks,
                'result': result['global_metrics']
            }
            
        except Exception as e:
            logger.error(f"âŒ å°è§„æ¨¡æµ‹è¯•å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    def medium_scale_test(self) -> dict:
        """ä¸­è§„æ¨¡æµ‹è¯•ï¼šå¤„ç†å¤§éƒ¨åˆ†æ•°æ®"""
        logger.info("ğŸ¯ === ä¸­è§„æ¨¡ä¼˜åŒ–æµ‹è¯• ===")
        
        try:
            optimizer = QuickFullScaleOptimizer(
                "./populaiton/æ¸©å·_population_grid.csv",
                "./å…¬äº¤ç«™ç‚¹shp/0577æ¸©å·.shp"
            )
            
            # ä¸­ç­‰è§„æ¨¡é™åˆ¶
            original_blocks = optimizer.spatial_blocks
            max_blocks = min(len(original_blocks), max(8, len(original_blocks) // 2))
            optimizer.spatial_blocks = original_blocks[:max_blocks]
            optimizer.n_processes = min(4, mp.cpu_count())
            
            logger.info(f"ğŸ“¦ å¤„ç†è§„æ¨¡: {len(optimizer.spatial_blocks)}/{len(original_blocks)} ä¸ªåŒºåŸŸ")
            
            # è¿è¡Œä¼˜åŒ–
            start_time = time.time()
            result = optimizer.optimize_full_scale()
            test_time = time.time() - start_time
            
            # åˆ›å»ºå¯è§†åŒ– (QuickFullScaleOptimizer æš‚ä¸æ”¯æŒ)
            # map_path = optimizer.create_full_scale_visualization(result, sample_ratio=0.15)
            map_path = "æš‚ä¸æ”¯æŒå¯è§†åŒ–"
            
            logger.info(f"âœ… ä¸­è§„æ¨¡æµ‹è¯•å®Œæˆï¼Œç”¨æ—¶ {test_time:.1f}ç§’")
            # logger.info(f"ğŸ—ºï¸  å¯è§†åŒ–åœ°å›¾: {map_path}")
            
            return {
                'status': 'success',
                'test_time': test_time,
                'blocks_processed': len(optimizer.spatial_blocks),
                'total_blocks': len(original_blocks),
                'result': result['global_metrics'],
                'map_path': map_path
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¸­è§„æ¨¡æµ‹è¯•å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    def run_full_scale_with_monitoring(self) -> dict:
        """è¿è¡Œå…¨è§„æ¨¡ä¼˜åŒ–ï¼ˆå¸¦ç›‘æ§ï¼‰"""
        logger.info("ğŸš€ === å…¨è§„æ¨¡ä¼˜åŒ–ï¼ˆç›‘æ§æ¨¡å¼ï¼‰ ===")
        
        try:
            # é¢„æ£€æŸ¥
            if self.system_info['memory_available_gb'] < 6:
                logger.warning("âš ï¸  å†…å­˜å¯èƒ½ä¸è¶³ï¼Œå»ºè®®å…ˆè¿è¡Œä¸­è§„æ¨¡æµ‹è¯•")
                return {'status': 'skipped', 'reason': 'insufficient_memory'}
            
            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = QuickFullScaleOptimizer(
                "./populaiton/æ¸©å·_population_grid.csv",
                "./å…¬äº¤ç«™ç‚¹shp/0577æ¸©å·.shp"
            )
            
            # æ€§èƒ½ç›‘æ§
            start_memory = psutil.virtual_memory().percent
            start_time = time.time()
            
            logger.info(f"ğŸ” å¼€å§‹ç›‘æ§ - åˆå§‹å†…å­˜ä½¿ç”¨: {start_memory:.1f}%")
            
            # è¿è¡Œä¼˜åŒ–
            result = optimizer.optimize_full_scale()
            
            end_time = time.time()
            end_memory = psutil.virtual_memory().percent
            
            # åˆ›å»ºå®Œæ•´å¯è§†åŒ– (QuickFullScaleOptimizer æš‚ä¸æ”¯æŒ)
            # map_path = optimizer.create_full_scale_visualization(result, sample_ratio=0.2)
            map_path = "æš‚ä¸æ”¯æŒå¯è§†åŒ–"
            
            logger.info(f"âœ… å…¨è§„æ¨¡ä¼˜åŒ–å®Œæˆ!")
            logger.info(f"â±ï¸  æ€»ç”¨æ—¶: {end_time - start_time:.1f}ç§’")
            logger.info(f"ğŸ’¾ å†…å­˜å˜åŒ–: {start_memory:.1f}% â†’ {end_memory:.1f}%")
            # logger.info(f"ğŸ—ºï¸  å®Œæ•´åœ°å›¾: {map_path}")
            
            return {
                'status': 'success',
                'total_time': end_time - start_time,
                'memory_change': end_memory - start_memory,
                'result': result,
                'map_path': map_path
            }
            
        except Exception as e:
            logger.error(f"âŒ å…¨è§„æ¨¡ä¼˜åŒ–å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    def run_progressive_test(self) -> dict:
        """æ¸è¿›å¼æµ‹è¯•ï¼šä»å°åˆ°å¤§é€æ­¥æµ‹è¯•"""
        logger.info("ğŸ“ˆ === æ¸è¿›å¼æµ‹è¯•æµç¨‹ ===")
        
        results = {}
        
        # 1. å¿«é€Ÿæµ‹è¯•
        logger.info("\nğŸ”¸ æ­¥éª¤1: å¿«é€ŸåŠŸèƒ½æµ‹è¯•")
        quick_result = self.quick_test()
        results['quick_test'] = quick_result
        
        if quick_result['status'] != 'success':
            logger.error("âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
            return results
        
        # 2. å°è§„æ¨¡æµ‹è¯•
        logger.info("\nğŸ”¸ æ­¥éª¤2: å°è§„æ¨¡ä¼˜åŒ–æµ‹è¯•")
        small_result = self.small_scale_test()
        results['small_scale'] = small_result
        
        if small_result['status'] != 'success':
            logger.error("âŒ å°è§„æ¨¡æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
            return results
        
        # 3. æ ¹æ®ç»“æœå†³å®šæ˜¯å¦è¿›è¡Œæ›´å¤§è§„æ¨¡æµ‹è¯•
        estimated_time = small_result.get('estimated_full_time', 0)
        
        if estimated_time > 1800:  # è¶…è¿‡30åˆ†é’Ÿ
            logger.warning(f"âš ï¸  é¢„ä¼°å…¨è§„æ¨¡æ—¶é—´è¿‡é•¿({estimated_time/60:.1f}åˆ†é’Ÿ)ï¼Œå»ºè®®ä½¿ç”¨ä¸­è§„æ¨¡æµ‹è¯•")
            
            logger.info("\nğŸ”¸ æ­¥éª¤3: ä¸­è§„æ¨¡ä¼˜åŒ–æµ‹è¯•")
            medium_result = self.medium_scale_test()
            results['medium_scale'] = medium_result
            
        else:
            logger.info(f"âœ… é¢„ä¼°æ—¶é—´åˆç†({estimated_time/60:.1f}åˆ†é’Ÿ)ï¼Œå¯ä»¥è¿›è¡Œå…¨è§„æ¨¡ä¼˜åŒ–")
            
            logger.info("\nğŸ”¸ æ­¥éª¤3: å…¨è§„æ¨¡ä¼˜åŒ–")
            full_result = self.run_full_scale_with_monitoring()
            results['full_scale'] = full_result
        
        # æ€»ç»“
        self._display_progressive_summary(results)
        
        return results
    
    def _display_progressive_summary(self, results: dict):
        """æ˜¾ç¤ºæ¸è¿›å¼æµ‹è¯•æ€»ç»“"""
        logger.info(f"\nğŸ“‹ === æ¸è¿›å¼æµ‹è¯•æ€»ç»“ ===")
        
        for test_name, result in results.items():
            if result['status'] == 'success':
                logger.info(f"âœ… {test_name}: æˆåŠŸ")
                if 'test_time' in result:
                    logger.info(f"   â±ï¸  ç”¨æ—¶: {result['test_time']:.1f}ç§’")
            else:
                logger.info(f"âŒ {test_name}: å¤±è´¥")
        
        # æ¨è
        if 'full_scale' in results and results['full_scale']['status'] == 'success':
            logger.info("\nğŸ† æ¨è: å…¨è§„æ¨¡ä¼˜åŒ–å·²æˆåŠŸå®Œæˆï¼")
        elif 'medium_scale' in results and results['medium_scale']['status'] == 'success':
            logger.info("\nğŸ’¡ æ¨è: ä¸­è§„æ¨¡æµ‹è¯•è¡¨ç°è‰¯å¥½ï¼Œå¯ä»¥å°è¯•å…¨è§„æ¨¡ä¼˜åŒ–")
        elif 'small_scale' in results and results['small_scale']['status'] == 'success':
            logger.info("\nâš ï¸  æ¨è: å»ºè®®ä¼˜åŒ–ç³»ç»Ÿèµ„æºåå†å°è¯•å¤§è§„æ¨¡ä¼˜åŒ–")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¸©å·å…¨è§„æ¨¡å…¬äº¤ä¼˜åŒ–æµ‹è¯•')
    parser.add_argument('--mode', choices=['quick', 'small', 'medium', 'full', 'progressive'], 
                       default='progressive', help='æµ‹è¯•æ¨¡å¼')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶è¿è¡Œï¼ˆå¿½ç•¥èµ„æºè­¦å‘Šï¼‰')
    
    args = parser.parse_args()
    
    # è®¾ç½®å¤šè¿›ç¨‹æ–¹å¼
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass  # å·²ç»è®¾ç½®è¿‡äº†
    
    # åˆ›å»ºæµ‹è¯•ç®¡ç†å™¨
    test_manager = FullScaleTestManager()
    
    try:
        if args.mode == 'quick':
            result = test_manager.quick_test()
        elif args.mode == 'small':
            result = test_manager.small_scale_test()
        elif args.mode == 'medium':
            result = test_manager.medium_scale_test()
        elif args.mode == 'full':
            result = test_manager.run_full_scale_with_monitoring()
        elif args.mode == 'progressive':
            result = test_manager.run_progressive_test()
        else:
            logger.error(f"æœªçŸ¥æµ‹è¯•æ¨¡å¼: {args.mode}")
            return
        
        logger.info(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼æ¨¡å¼: {args.mode}")
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")


if __name__ == "__main__":
    main()