"""
å…¨è§„æ¨¡ä¼˜åŒ–å™¨ - ä¿®å¤ç‰ˆæœ¬
è§£å†³Windowså¤šè¿›ç¨‹å…¼å®¹æ€§é—®é¢˜
"""

import numpy as np
import pandas as pd
from numba import jit, prange
import logging
import time
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Dict, Any, List, Tuple
import gc
import psutil
import folium
from folium import plugins
import matplotlib.pyplot as plt
from pathlib import Path
import pickle
import json
import os

from data_preprocessing import DataProcessor
from acceleration_utils import fast_population_coverage

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…¨å±€å‡½æ•°ï¼Œé¿å…pickleé—®é¢˜
def simple_worker_func(x):
    """å…¨å±€å·¥ä½œå‡½æ•°"""
    return x * x

def optimize_block_worker(block_info):
    """ä¼˜åŒ–å•ä¸ªåŒºåŸŸçš„å·¥ä½œå‡½æ•°"""
    try:
        block_data, coverage_radius = block_info
        return _optimize_single_block(block_data, coverage_radius)
    except Exception as e:
        logger.error(f"åŒºåŸŸä¼˜åŒ–å¤±è´¥: {e}")
        return {'status': 'error', 'error': str(e)}

def _optimize_single_block(block_data: Dict, coverage_radius: float) -> Dict[str, Any]:
    """ä¼˜åŒ–å•ä¸ªåŒºåŸŸ"""
    block_id = block_data['bounds']['block_id']
    
    logger.info(f"ğŸ”„ ä¼˜åŒ–åŒºåŸŸ {block_id}...")
    start_time = time.time()
    
    # æå–æ•°æ®
    pop_data = block_data['population_data']
    stop_data = block_data['bus_stops_data']
    
    if len(stop_data) == 0:
        return {'block_id': block_id, 'status': 'empty', 'result': None}
    
    # æ•°æ®é¢„å¤„ç†
    pop_points = pop_data[['longitude', 'latitude']].values
    pop_weights = pop_data['population'].values
    original_positions = stop_data[['longitude', 'latitude']].values
    stop_indices = stop_data['stop_idx'].values
    
    # æ ¹æ®å—å¤§å°è°ƒæ•´å‚æ•°
    n_stops = len(original_positions)
    
    if n_stops < 50:
        population_size, generations = 20, 20
    elif n_stops < 200:
        population_size, generations = 30, 30
    elif n_stops < 500:
        population_size, generations = 40, 40
    else:
        population_size, generations = 50, 50
    
    # æ‰§è¡Œç®€åŒ–çš„ä¼˜åŒ–ç®—æ³•
    optimized_positions, best_fitness = _simplified_genetic_algorithm(
        original_positions, pop_points, pop_weights, coverage_radius,
        population_size, generations
    )
    
    optimization_time = time.time() - start_time
    
    # è®¡ç®—ç»“æœç»Ÿè®¡
    coverage = fast_population_coverage(
        optimized_positions, pop_points, pop_weights, coverage_radius
    )
    
    moved_count = 0
    total_movement = 0.0
    
    for i in range(len(original_positions)):
        dx = optimized_positions[i, 0] - original_positions[i, 0]
        dy = optimized_positions[i, 1] - original_positions[i, 1]
        movement = np.sqrt(dx * dx + dy * dy) * 111.32 * 1000  # è½¬æ¢ä¸ºç±³
        
        if movement > 10:  # ç§»åŠ¨è¶…è¿‡10ç±³
            moved_count += 1
        total_movement += movement
    
    result = {
        'block_id': block_id,
        'status': 'success',
        'optimization_time': optimization_time,
        'n_stops': n_stops,
        'n_population': len(pop_points),
        'coverage': coverage,
        'moved_stations': moved_count,
        'total_movement_m': total_movement,
        'average_movement_m': total_movement / n_stops,
        'best_fitness': best_fitness,
        'original_positions': original_positions,
        'optimized_positions': optimized_positions,
        'stop_indices': stop_indices
    }
    
    logger.info(f"âœ… åŒºåŸŸ {block_id} å®Œæˆ: "
               f"è¦†ç›–ç‡{coverage:.3f}, ç§»åŠ¨{moved_count}ç«™ç‚¹, "
               f"ç”¨æ—¶{optimization_time:.1f}s")
    
    return result

@jit(nopython=True, cache=True)
def _simplified_genetic_algorithm(original_positions: np.ndarray,
                                pop_points: np.ndarray,
                                pop_weights: np.ndarray,
                                coverage_radius: float,
                                population_size: int,
                                generations: int) -> Tuple[np.ndarray, float]:
    """ç®€åŒ–çš„é—ä¼ ç®—æ³•ï¼ˆnumbaä¼˜åŒ–ï¼‰"""
    n_stops = len(original_positions)
    
    # åˆå§‹åŒ–ç§ç¾¤
    population = np.zeros((population_size, n_stops, 2))
    for i in range(population_size):
        population[i] = original_positions.copy()
        
        # åªç§»åŠ¨å°‘æ•°ç«™ç‚¹
        n_move = max(1, int(n_stops * 0.15))
        for _ in range(n_move):
            idx = np.random.randint(0, n_stops)
            dx = np.random.normal(0, 0.001)
            dy = np.random.normal(0, 0.001)
            population[i, idx, 0] += dx
            population[i, idx, 1] += dy
    
    best_individual = population[0].copy()
    best_fitness = -np.inf
    
    for generation in range(generations):
        # è®¡ç®—é€‚åº”åº¦
        fitness_scores = np.zeros(population_size)
        
        for i in range(population_size):
            # è®¡ç®—è¦†ç›–ç‡
            coverage = fast_population_coverage(
                population[i], pop_points, pop_weights, coverage_radius
            )
            
            # è®¡ç®—ç¨³å®šæ€§
            total_movement = 0.0
            unmoved_count = 0
            
            for j in range(n_stops):
                dx = population[i, j, 0] - original_positions[j, 0]
                dy = population[i, j, 1] - original_positions[j, 1]
                movement = np.sqrt(dx * dx + dy * dy)
                
                total_movement += movement
                if movement < 0.0001:
                    unmoved_count += 1
            
            # å¤åˆé€‚åº”åº¦
            stability = unmoved_count / n_stops
            fitness_scores[i] = 3.0 * coverage + 2.0 * stability - 0.5 * total_movement
            
            if fitness_scores[i] > best_fitness:
                best_fitness = fitness_scores[i]
                best_individual = population[i].copy()
        
        # æ–°ç§ç¾¤ç”Ÿæˆï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        new_population = np.zeros_like(population)
        
        # ä¿ç•™æœ€ä½³ä¸ªä½“
        best_idx = np.argmax(fitness_scores)
        new_population[0] = population[best_idx]
        
        # ç”Ÿæˆæ–°ä¸ªä½“
        for i in range(1, population_size):
            # é€‰æ‹©çˆ¶æ¯
            parent_idx = _tournament_select_simple(fitness_scores)
            child = population[parent_idx].copy()
            
            # å˜å¼‚
            if np.random.random() < 0.2:
                for _ in range(max(1, int(n_stops * 0.05))):
                    idx = np.random.randint(0, n_stops)
                    child[idx, 0] += np.random.normal(0, 0.0005)
                    child[idx, 1] += np.random.normal(0, 0.0005)
            
            new_population[i] = child
        
        population = new_population
    
    return best_individual, best_fitness

@jit(nopython=True, cache=True)
def _tournament_select_simple(fitness_scores: np.ndarray) -> int:
    """ç®€å•é”¦æ ‡èµ›é€‰æ‹©"""
    pop_size = len(fitness_scores)
    idx1 = np.random.randint(0, pop_size)
    idx2 = np.random.randint(0, pop_size)
    idx3 = np.random.randint(0, pop_size)
    
    if fitness_scores[idx1] >= fitness_scores[idx2] and fitness_scores[idx1] >= fitness_scores[idx3]:
        return idx1
    elif fitness_scores[idx2] >= fitness_scores[idx3]:
        return idx2
    else:
        return idx3

class QuickFullScaleOptimizer:
    """å¿«é€Ÿå…¨è§„æ¨¡ä¼˜åŒ–å™¨"""
    
    def __init__(self, population_csv_path: str, bus_stops_shp_path: str):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        logger.info("ğŸš€ åˆå§‹åŒ–å¿«é€Ÿå…¨è§„æ¨¡ä¼˜åŒ–å™¨...")
        
        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        memory = psutil.virtual_memory()
        cpu_count = mp.cpu_count()
        
        logger.info(f"ğŸ’» ç³»ç»Ÿèµ„æº:")
        logger.info(f"   CPU: {cpu_count} æ ¸å¿ƒ")
        logger.info(f"   å†…å­˜: {memory.available / (1024**3):.1f}GB å¯ç”¨")
        
        # åŠ è½½æ•°æ®
        processor = DataProcessor(population_csv_path, bus_stops_shp_path)
        self.population_data, self.bus_stops_data, _ = processor.get_processed_data()
        
        # æ·»åŠ ç´¢å¼•
        self.population_data = self.population_data.reset_index(drop=True)
        self.bus_stops_data = self.bus_stops_data.reset_index(drop=True)
        self.bus_stops_data['stop_idx'] = range(len(self.bus_stops_data))
        
        # åˆ›å»ºç©ºé—´åˆ†å—
        self._create_spatial_blocks()
        
        # ä¼˜åŒ–å‚æ•°
        self.coverage_radius = 0.008
        self.n_processes = min(cpu_count, 8)  # é™åˆ¶æœ€å¤§è¿›ç¨‹æ•°
        
        logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"   æ•°æ®: {len(self.population_data)} äººå£ç‚¹, {len(self.bus_stops_data)} ç«™ç‚¹")
        logger.info(f"   åˆ†å—: {len(self.spatial_blocks)} ä¸ªåŒºåŸŸ")
        logger.info(f"   è¿›ç¨‹: {self.n_processes} ä¸ª")
    
    def _create_spatial_blocks(self):
        """åˆ›å»ºç©ºé—´åˆ†å—"""
        logger.info("ğŸ—ºï¸  åˆ›å»ºç©ºé—´åˆ†å—...")
        
        # è®¡ç®—è¾¹ç•Œ
        all_lons = np.concatenate([
            self.population_data['longitude'].values,
            self.bus_stops_data['longitude'].values
        ])
        all_lats = np.concatenate([
            self.population_data['latitude'].values,
            self.bus_stops_data['latitude'].values
        ])
        
        min_lon, max_lon = all_lons.min(), all_lons.max()
        min_lat, max_lat = all_lats.min(), all_lats.max()
        
        # åŠ¨æ€ç½‘æ ¼å¤§å°
        target_stations_per_block = 800
        total_stations = len(self.bus_stops_data)
        n_blocks = max(4, total_stations // target_stations_per_block)
        
        # ç½‘æ ¼ç»´åº¦
        lon_range = max_lon - min_lon
        lat_range = max_lat - min_lat
        aspect_ratio = lon_range / lat_range
        
        grid_cols = max(2, int(np.sqrt(n_blocks * aspect_ratio)))
        grid_rows = max(2, int(n_blocks / grid_cols))
        
        # åˆ›å»ºç½‘æ ¼
        lon_step = lon_range / grid_cols
        lat_step = lat_range / grid_rows
        
        self.spatial_blocks = []
        
        for row in range(grid_rows):
            for col in range(grid_cols):
                # å—è¾¹ç•Œ
                block_min_lon = min_lon + col * lon_step
                block_max_lon = min_lon + (col + 1) * lon_step
                block_min_lat = min_lat + row * lat_step
                block_max_lat = min_lat + (row + 1) * lat_step
                
                # æ·»åŠ è¾¹ç•Œç¼“å†²
                margin = 0.005
                if col > 0:
                    block_min_lon -= margin
                if col < grid_cols - 1:
                    block_max_lon += margin
                if row > 0:
                    block_min_lat -= margin
                if row < grid_rows - 1:
                    block_max_lat += margin
                
                # ç­›é€‰æ•°æ®
                pop_mask = (
                    (self.population_data['longitude'] >= block_min_lon) &
                    (self.population_data['longitude'] <= block_max_lon) &
                    (self.population_data['latitude'] >= block_min_lat) &
                    (self.population_data['latitude'] <= block_max_lat)
                )
                
                stop_mask = (
                    (self.bus_stops_data['longitude'] >= block_min_lon) &
                    (self.bus_stops_data['longitude'] <= block_max_lon) &
                    (self.bus_stops_data['latitude'] >= block_min_lat) &
                    (self.bus_stops_data['latitude'] <= block_max_lat)
                )
                
                block_pop = self.population_data[pop_mask].copy()
                block_stops = self.bus_stops_data[stop_mask].copy()
                
                if len(block_stops) > 0:
                    block = {
                        'bounds': {
                            'block_id': f"block_{row}_{col}",
                            'min_lon': block_min_lon,
                            'max_lon': block_max_lon,
                            'min_lat': block_min_lat,
                            'max_lat': block_max_lat
                        },
                        'population_data': block_pop,
                        'bus_stops_data': block_stops,
                        'n_population': len(block_pop),
                        'n_stops': len(block_stops)
                    }
                    self.spatial_blocks.append(block)
        
        logger.info(f"âœ… åˆ†å—å®Œæˆ: {len(self.spatial_blocks)} ä¸ªåŒºåŸŸ")
        for i, block in enumerate(self.spatial_blocks):
            logger.info(f"   åŒºåŸŸ{i+1}: {block['n_stops']}ç«™ç‚¹, {block['n_population']}äººå£")
    
    def optimize_full_scale(self) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨è§„æ¨¡ä¼˜åŒ–"""
        logger.info(f"ğŸš€ å¼€å§‹å…¨è§„æ¨¡ä¼˜åŒ–...")
        logger.info(f"   å¤„ç† {len(self.spatial_blocks)} ä¸ªåŒºåŸŸ")
        logger.info(f"   ä½¿ç”¨ {self.n_processes} ä¸ªè¿›ç¨‹")
        
        start_time = time.time()
        
        # å‡†å¤‡ä»»åŠ¡æ•°æ®
        block_tasks = [(block, self.coverage_radius) for block in self.spatial_blocks]
        
        # ä¸²è¡Œå¤„ç†å„åŒºåŸŸï¼ˆé¿å…å¤šè¿›ç¨‹é—®é¢˜ï¼‰
        all_results = []
        
        logger.info("ğŸ”„ é‡‡ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼ä»¥ç¡®ä¿ç¨³å®šæ€§...")
        
        for i, (block, coverage_radius) in enumerate(block_tasks, 1):
            try:
                logger.info(f"ğŸ”„ å¤„ç†åŒºåŸŸ {i}/{len(block_tasks)}: {block['bounds']['block_id']}...")
                
                # ç›´æ¥è°ƒç”¨ä¼˜åŒ–å‡½æ•°
                result = _optimize_single_block(block, coverage_radius)
                
                if result.get('status') == 'success':
                    all_results.append(result)
                    # å®‰å…¨è®¿é—®metricså­—æ®µ
                    metrics = result.get('metrics', {})
                    coverage_rate = metrics.get('coverage_rate', 0)
                    moved_stations = metrics.get('moved_stations', 0)
                    optimization_time = metrics.get('optimization_time', 0)
                    logger.info(f"âœ… åŒºåŸŸ {result['block_id']} å®Œæˆ: è¦†ç›–ç‡{coverage_rate:.3f}, ç§»åŠ¨{moved_stations}ç«™ç‚¹, ç”¨æ—¶{optimization_time:.1f}s")
                else:
                    logger.error(f"âŒ åŒºåŸŸ {i} ä¼˜åŒ–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
                # å¼ºåˆ¶åƒåœ¾å›æ”¶
                gc.collect()
                
            except Exception as e:
                logger.error(f"âŒ åŒºåŸŸ {i} å¤„ç†å¤±è´¥: {e}")
                
        # å¦‚æœä¸²è¡Œå¤„ç†ä¹Ÿæœ‰é—®é¢˜ï¼Œå°è¯•æ›´ä¿å®ˆçš„å¤šè¿›ç¨‹
        if len(all_results) < len(block_tasks) // 2:
            logger.warning("ğŸ”„ ä¸²è¡Œå¤„ç†æ•ˆæœä¸ä½³ï¼Œå°è¯•ä¿å®ˆå¤šè¿›ç¨‹æ¨¡å¼...")
            all_results = []
            
            # æä¿å®ˆçš„å¤šè¿›ç¨‹è®¾ç½®
            effective_processes = min(2, self.n_processes)
            with ProcessPoolExecutor(max_workers=effective_processes) as executor:
                for i, task in enumerate(block_tasks, 1):
                    try:
                        future = executor.submit(optimize_block_worker, task)
                        result = future.result(timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
                        
                        if result.get('status') == 'success':
                            all_results.append(result)
                            logger.info(f"ğŸ“¦ å®ŒæˆåŒºåŸŸ {i}/{len(block_tasks)}: {result.get('block_id', 'æœªçŸ¥')}")
                        else:
                            logger.error(f"âŒ åŒºåŸŸ {i} ä¼˜åŒ–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    except Exception as e:
                        logger.error(f"âŒ åŒºåŸŸ {i} å¤„ç†å¤±è´¥: {e}")
        
        total_time = time.time() - start_time
        
        # åˆå¹¶ç»“æœ
        final_result = self._merge_results(all_results, total_time)
        
        # æ˜¾ç¤ºç»“æœ
        self._display_results(final_result)
        
        # ä¿å­˜ç»“æœ
        self._save_results(final_result)
        
        return final_result
    
    def _merge_results(self, block_results: List[Dict], total_time: float) -> Dict[str, Any]:
        """åˆå¹¶å—ç»“æœ"""
        logger.info("ğŸ”— åˆå¹¶ä¼˜åŒ–ç»“æœ...")
        
        successful_results = [r for r in block_results if r.get('status') == 'success']
        
        if not successful_results:
            raise RuntimeError("æ‰€æœ‰åŒºåŸŸä¼˜åŒ–éƒ½å¤±è´¥äº†ï¼")
        
        # ç»Ÿè®¡å…¨å±€æŒ‡æ ‡
        total_stations = sum(r['n_stops'] for r in successful_results)
        total_population = sum(r['n_population'] for r in successful_results)
        total_moved = sum(r['moved_stations'] for r in successful_results)
        total_movement = sum(r['total_movement_m'] for r in successful_results)
        
        # è®¡ç®—åŠ æƒè¦†ç›–ç‡
        weighted_coverage = sum(r['coverage'] * r['n_population'] for r in successful_results)
        global_coverage = weighted_coverage / total_population if total_population > 0 else 0
        
        # æ„å»ºç»“æœ
        result = {
            'optimization_time': total_time,
            'successful_blocks': len(successful_results),
            'failed_blocks': len(block_results) - len(successful_results),
            'global_metrics': {
                'total_stations': total_stations,
                'total_population': total_population,
                'moved_stations': total_moved,
                'total_movement_m': total_movement,
                'average_movement_m': total_movement / total_stations if total_stations > 0 else 0,
                'global_coverage': global_coverage,
                'stability_score': 1.0 - (total_moved / total_stations) if total_stations > 0 else 1.0
            },
            'block_results': successful_results
        }
        
        return result
    
    def _display_results(self, result: Dict[str, Any]):
        """æ˜¾ç¤ºç»“æœ"""
        logger.info(f"\nğŸ‰ === å…¨è§„æ¨¡ä¼˜åŒ–å®Œæˆ === ğŸ‰")
        logger.info(f"â±ï¸  æ€»ä¼˜åŒ–æ—¶é—´: {result['optimization_time']:.1f}ç§’")
        logger.info(f"âœ… æˆåŠŸå¤„ç†: {result['successful_blocks']} ä¸ªåŒºåŸŸ")
        logger.info(f"âŒ å¤±è´¥å¤„ç†: {result['failed_blocks']} ä¸ªåŒºåŸŸ")
        
        metrics = result['global_metrics']
        logger.info(f"\nğŸ“Š å…¨å±€ä¼˜åŒ–æŒ‡æ ‡:")
        logger.info(f"   ğŸ¢ æ€»ç«™ç‚¹æ•°: {metrics['total_stations']:,}")
        logger.info(f"   ğŸ‘¥ æ€»äººå£æ•°: {metrics['total_population']:,}")
        logger.info(f"   ğŸ¯ å…¨å±€è¦†ç›–ç‡: {metrics['global_coverage']:.4f} ({metrics['global_coverage']*100:.2f}%)")
        logger.info(f"   ğŸšŒ ç§»åŠ¨ç«™ç‚¹: {metrics['moved_stations']:,} ({metrics['moved_stations']/metrics['total_stations']*100:.1f}%)")
        logger.info(f"   ğŸ“ å¹³å‡ç§»åŠ¨: {metrics['average_movement_m']:.0f}ç±³")
        logger.info(f"   â­ ç¨³å®šæ€§: {metrics['stability_score']:.4f}")
        
        # è®¡ç®—æœåŠ¡äººå£
        covered_population = metrics['global_coverage'] * metrics['total_population']
        logger.info(f"   ğŸ‘¥ æœåŠ¡äººå£: {covered_population:,.0f} äºº")
    
    def _save_results(self, result: Dict[str, Any]):
        """ä¿å­˜ç»“æœ"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_dir = Path(f"full_scale_results_{timestamp}")
        output_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æ‘˜è¦
        summary = {
            'optimization_time': result['optimization_time'],
            'successful_blocks': result['successful_blocks'],
            'global_metrics': result['global_metrics'],
            'timestamp': timestamp
        }
        
        with open(output_dir / "summary.json", 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")


def quick_test():
    """å¿«é€Ÿæµ‹è¯•"""
    logger.info("ğŸš€ === å¿«é€Ÿå…¨è§„æ¨¡ä¼˜åŒ–æµ‹è¯• === ğŸš€")
    
    try:
        # å¿«é€Ÿå¤šè¿›ç¨‹æµ‹è¯•
        logger.info("ğŸ”„ æµ‹è¯•å¤šè¿›ç¨‹...")
        with ProcessPoolExecutor(max_workers=2) as executor:
            futures = [executor.submit(simple_worker_func, i) for i in range(5)]
            results = [f.result() for f in futures]
        logger.info(f"âœ… å¤šè¿›ç¨‹æµ‹è¯•æˆåŠŸ: {results}")
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = QuickFullScaleOptimizer(
            "./populaiton/æ¸©å·_population_grid.csv", 
            "./å…¬äº¤ç«™ç‚¹shp/0577æ¸©å·.shp"
        )
        
        # è¿è¡Œä¼˜åŒ–
        result = optimizer.optimize_full_scale()
        
        logger.info(f"\nğŸ† ä¼˜åŒ–æˆåŠŸå®Œæˆï¼")
        return result
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    if os.name == 'nt':  # Windows
        mp.set_start_method('spawn', force=True)
    
    quick_test()