"""
åŸºäºæˆåŠŸç®—æ³•çš„å®Œæ•´è¾“å‡ºç‰ˆæœ¬
ä½¿ç”¨ final_optimizer.py çš„æ ¸å¿ƒç®—æ³•ï¼Œå¢åŠ å®Œæ•´çš„æ–‡ä»¶è¾“å‡ºåŠŸèƒ½
"""

import numpy as np
import pandas as pd
from numba import jit, prange
import logging
import time
from typing import Dict, Any, Tuple
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
import json

try:
    import geopandas as gpd
    HAS_GEOPANDAS = True
except ImportError:
    HAS_GEOPANDAS = False
    print("Warning: GeoPandas not available, will create CSV files instead")

from data_preprocessing import DataProcessor
from acceleration_utils import fast_population_coverage

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@jit(nopython=True, cache=True)
def intelligent_initialization(original_positions: np.ndarray,
                             population_size: int,
                             max_move_ratio: float = 0.15,
                             max_move_distance: float = 0.003) -> np.ndarray:
    """
    æ™ºèƒ½åˆå§‹åŒ–ï¼šç²¾ç¡®æ§åˆ¶ç§»åŠ¨ç­–ç•¥
    - å¤§éƒ¨åˆ†ä¸ªä½“å‡ ä¹ä¸ç§»åŠ¨
    - å°‘æ•°ä¸ªä½“è¿›è¡Œæˆ˜ç•¥æ€§è°ƒæ•´
    """
    n_stops = original_positions.shape[0]
    population = np.zeros((population_size, n_stops, 2))
    
    for i in range(population_size):
        population[i] = original_positions.copy()
        
        # æ¯ä¸ªä¸ªä½“åªç§»åŠ¨10-20%çš„ç«™ç‚¹
        n_move = max(1, int(n_stops * (0.1 + np.random.random() * max_move_ratio)))
        move_indices = np.random.choice(n_stops, n_move, replace=False)
        
        for idx in move_indices:
            # æ¸è¿›å¼ç§»åŠ¨ï¼šè·ç¦»æŒ‰æ­£æ€åˆ†å¸ƒ
            move_distance = np.abs(np.random.normal(0, max_move_distance * 0.3))
            move_distance = min(move_distance, max_move_distance)
            
            # éšæœºæ–¹å‘
            angle = np.random.random() * 2 * np.pi
            dx = move_distance * np.cos(angle)
            dy = move_distance * np.sin(angle)
            
            population[i, idx, 0] += dx
            population[i, idx, 1] += dy
    
    return population

@jit(nopython=True, cache=True)
def stability_aware_fitness(positions: np.ndarray,
                          original_positions: np.ndarray,
                          pop_points: np.ndarray,
                          pop_weights: np.ndarray,
                          coverage_radius: float) -> float:
    """
    ç¨³å®šæ€§æ„ŸçŸ¥é€‚åº”åº¦å‡½æ•°
    ä¼˜å…ˆè€ƒè™‘ï¼šè¦†ç›–ç‡ > ç¨³å®šæ€§ > æœ€å°ç§»åŠ¨
    """
    n_stops = positions.shape[0]
    
    # 1. è¦†ç›–ç‡è®¡ç®—
    coverage_rate = fast_population_coverage(
        positions, pop_points, pop_weights, coverage_radius
    )
    
    # 2. ç¨³å®šæ€§è®¡ç®—
    unmoved_count = 0
    total_movement = 0.0
    movement_penalty = 0.0
    
    for i in range(n_stops):
        dx = positions[i, 0] - original_positions[i, 0]
        dy = positions[i, 1] - original_positions[i, 1]
        movement = np.sqrt(dx * dx + dy * dy)
        
        total_movement += movement
        
        # ç¨³å®šæ€§ï¼šç§»åŠ¨å°äºé˜ˆå€¼è®¤ä¸ºæœªç§»åŠ¨
        if movement < 0.0001:  # ~11ç±³
            unmoved_count += 1
        else:
            # ç§»åŠ¨æƒ©ç½šï¼šè¶…å‡ºåˆç†èŒƒå›´å¤§å¹…æƒ©ç½š
            if movement > 0.005:  # ~550ç±³
                movement_penalty += movement * 10
            else:
                movement_penalty += movement
    
    stability_score = unmoved_count / n_stops
    avg_movement = total_movement / n_stops
    
    # ç»¼åˆé€‚åº”åº¦ï¼šä¼˜å…ˆè¦†ç›–ç‡ï¼Œå…¼é¡¾ç¨³å®šæ€§
    fitness = (
        coverage_rate * 10.0 +           # è¦†ç›–ç‡æƒé‡æœ€é«˜
        stability_score * 5.0 -          # ç¨³å®šæ€§å¥–åŠ±
        movement_penalty * 2.0           # ç§»åŠ¨æƒ©ç½š
    )
    
    return fitness

@jit(nopython=True, cache=True)
def adaptive_genetic_algorithm(original_positions: np.ndarray,
                             pop_points: np.ndarray,
                             pop_weights: np.ndarray,
                             coverage_radius: float,
                             population_size: int = 50,
                             max_generations: int = 100) -> Tuple[np.ndarray, float]:
    """è‡ªé€‚åº”é—ä¼ ç®—æ³•"""
    
    # æ™ºèƒ½åˆå§‹åŒ–
    population = intelligent_initialization(original_positions, population_size)
    
    best_individual = population[0].copy()
    best_fitness = stability_aware_fitness(
        best_individual, original_positions, pop_points, pop_weights, coverage_radius
    )
    
    stagnation_count = 0
    
    for generation in range(max_generations):
        # è®¡ç®—é€‚åº”åº¦
        fitness_scores = np.zeros(population_size)
        
        for i in range(population_size):
            fitness_scores[i] = stability_aware_fitness(
                population[i], original_positions, pop_points, pop_weights, coverage_radius
            )
            
            if fitness_scores[i] > best_fitness:
                best_fitness = fitness_scores[i]
                best_individual = population[i].copy()
                stagnation_count = 0
            else:
                stagnation_count += 1
        
        # æ—©åœç­–ç•¥
        if stagnation_count > 20:
            break
        
        # é€‰æ‹©æ’åº
        sorted_indices = np.argsort(fitness_scores)[::-1]
        
        # ç²¾è‹±ä¿ç•™
        elite_size = max(2, population_size // 10)
        new_population = np.zeros_like(population)
        
        for i in range(elite_size):
            new_population[i] = population[sorted_indices[i]].copy()
        
        # ç”Ÿæˆæ–°ä¸ªä½“
        for i in range(elite_size, population_size):
            # é”¦æ ‡èµ›é€‰æ‹©
            parent1_idx = sorted_indices[np.random.randint(0, min(5, population_size))]
            parent2_idx = sorted_indices[np.random.randint(0, min(5, population_size))]
            
            # ä¿å®ˆäº¤å‰
            child = population[parent1_idx].copy()
            
            # åªå¯¹10%çš„ç«™ç‚¹è¿›è¡Œäº¤å‰
            n_crossover = max(1, int(original_positions.shape[0] * 0.1))
            crossover_indices = np.random.choice(
                original_positions.shape[0], n_crossover, replace=False
            )
            
            for idx in crossover_indices:
                if np.random.random() < 0.5:
                    child[idx] = population[parent2_idx, idx].copy()
            
            # ä¿å®ˆå˜å¼‚
            if np.random.random() < 0.3:
                n_mutate = max(1, int(original_positions.shape[0] * 0.05))
                mutate_indices = np.random.choice(
                    original_positions.shape[0], n_mutate, replace=False
                )
                
                for idx in mutate_indices:
                    dx = np.random.normal(0, 0.001)
                    dy = np.random.normal(0, 0.001)
                    child[idx, 0] += dx
                    child[idx, 1] += dy
            
            new_population[i] = child
        
        population = new_population
    
    return best_individual, best_fitness

class FinalOptimizerWithOutputs:
    """ç»ˆæä¼˜åŒ–å™¨ - å®Œæ•´è¾“å‡ºç‰ˆæœ¬"""
    
    def __init__(self, population_csv_path: str, bus_stops_shp_path: str):
        """åˆå§‹åŒ–"""
        logger.info("ğŸš€ åˆå§‹åŒ–ç»ˆæä¼˜åŒ–å™¨ï¼ˆå®Œæ•´è¾“å‡ºç‰ˆï¼‰...")
        
        self.coverage_radius = 300  # 300ç±³è¦†ç›–åŠå¾„
        
        # æ•°æ®é¢„å¤„ç†
        self.processor = DataProcessor(population_csv_path, bus_stops_shp_path)
        self.population_data, self.bus_stops_data, self.overlap_info = self.processor.get_processed_data()
        
        logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ:")
        logger.info(f"   äººå£ç½‘æ ¼: {len(self.population_data):,}")
        logger.info(f"   å…¬äº¤ç«™ç‚¹: {len(self.bus_stops_data):,}")
        logger.info(f"   è¦†ç›–åŠå¾„: {self.coverage_radius}ç±³")
        
        self.output_dir = None
    
    def optimize_and_save_results(self) -> str:
        """æ‰§è¡Œä¼˜åŒ–å¹¶ä¿å­˜å®Œæ•´ç»“æœ"""
        logger.info("ğŸ¯ å¼€å§‹ä¼˜åŒ–å¹¶ä¿å­˜ç»“æœ...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = Path(f"final_optimization_results_{timestamp}")
        self.output_dir.mkdir(exist_ok=True)
        
        logger.info(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {self.output_dir}")
        
        # æ•°æ®å‡†å¤‡
        original_positions = self.bus_stops_data[['longitude', 'latitude']].values
        pop_points = self.population_data[['longitude', 'latitude']].values
        pop_weights = self.population_data['population'].values
        
        # æ‰§è¡Œä¼˜åŒ–
        logger.info("âš¡ æ‰§è¡Œé—ä¼ ç®—æ³•ä¼˜åŒ–...")
        start_time = time.time()
        
        optimized_positions, best_fitness = adaptive_genetic_algorithm(
            original_positions, pop_points, pop_weights, 
            self.coverage_radius / 111320.0,  # è½¬æ¢ä¸ºåº¦
            population_size=60, max_generations=100
        )
        
        optimization_time = time.time() - start_time
        
        logger.info(f"âœ… ä¼˜åŒ–å®Œæˆï¼Œç”¨æ—¶ {optimization_time:.2f}ç§’")
        logger.info(f"ğŸ¯ æœ€ä½³é€‚åº”åº¦: {best_fitness:.4f}")
        
        # è®¡ç®—è¯¦ç»†ç»Ÿè®¡
        results = self._calculate_detailed_stats(
            original_positions, optimized_positions, 
            pop_points, pop_weights, optimization_time
        )
        
        # ä¿å­˜æ‰€æœ‰ç»“æœ
        self._save_all_results(original_positions, optimized_positions, results)
        
        logger.info(f"ğŸ‰ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")
        return str(self.output_dir)
    
    def _calculate_detailed_stats(self, original_positions, optimized_positions, 
                                pop_points, pop_weights, optimization_time):
        """è®¡ç®—è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("ğŸ“Š è®¡ç®—è¯¦ç»†ç»Ÿè®¡...")
        
        n_stops = len(original_positions)
        
        # è¦†ç›–ç‡è®¡ç®—
        original_coverage = fast_population_coverage(
            original_positions, pop_points, pop_weights, self.coverage_radius / 111320.0
        )
        optimized_coverage = fast_population_coverage(
            optimized_positions, pop_points, pop_weights, self.coverage_radius / 111320.0
        )
        
        # ç§»åŠ¨ç»Ÿè®¡
        movements = []
        moved_count = 0
        total_movement_m = 0.0
        
        for i in range(n_stops):
            dx = optimized_positions[i, 0] - original_positions[i, 0]
            dy = optimized_positions[i, 1] - original_positions[i, 1]
            movement_deg = np.sqrt(dx * dx + dy * dy)
            movement_m = movement_deg * 111320.0
            
            movements.append(movement_m)
            total_movement_m += movement_m
            
            if movement_m > 10.0:  # ç§»åŠ¨è¶…è¿‡10ç±³
                moved_count += 1
        
        stability_score = (n_stops - moved_count) / n_stops
        
        results = {
            'optimization_time': optimization_time,
            'total_stations': n_stops,
            'moved_stations': moved_count,
            'stability_score': stability_score,
            'original_coverage': original_coverage,
            'optimized_coverage': optimized_coverage,
            'coverage_improvement': optimized_coverage - original_coverage,
            'total_movement_m': total_movement_m,
            'average_movement_m': total_movement_m / n_stops,
            'movements': movements,
            'original_positions': original_positions,
            'optimized_positions': optimized_positions
        }
        
        logger.info(f"ğŸ“ˆ ç»Ÿè®¡å®Œæˆ:")
        logger.info(f"   ç§»åŠ¨ç«™ç‚¹: {moved_count}/{n_stops} ({moved_count/n_stops:.1%})")
        logger.info(f"   ç¨³å®šæ€§: {stability_score:.3f}")
        logger.info(f"   è¦†ç›–ç‡: {original_coverage:.3f} â†’ {optimized_coverage:.3f}")
        logger.info(f"   å¹³å‡ç§»åŠ¨: {total_movement_m/n_stops:.1f}ç±³")
        
        return results
    
    def _save_all_results(self, original_positions, optimized_positions, results):
        """ä¿å­˜æ‰€æœ‰ç»“æœæ–‡ä»¶"""
        logger.info("ğŸ’¾ ä¿å­˜ç»“æœæ–‡ä»¶...")
        
        # 1. ä¿å­˜ç«™ç‚¹æ•°æ®
        self._save_station_data(original_positions, optimized_positions, results)
        
        # 2. ä¿å­˜äººå£æ•°æ®
        self._save_population_data()
        
        # 3. åˆ›å»ºå¯è§†åŒ–
        self._create_visualizations(results)
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        self._create_comprehensive_report(results)
        
        # 5. ä¿å­˜ç»Ÿè®¡JSON
        self._save_statistics_json(results)
    
    def _save_station_data(self, original_positions, optimized_positions, results):
        """ä¿å­˜ç«™ç‚¹æ•°æ®æ–‡ä»¶"""
        logger.info("ğŸšŒ ä¿å­˜ç«™ç‚¹æ•°æ®...")
        
        # åˆ›å»ºä¼˜åŒ–åçš„ç«™ç‚¹æ•°æ®
        optimized_stops = self.bus_stops_data.copy()
        
        # æ·»åŠ åˆ†æå­—æ®µ
        optimized_stops['original_lon'] = original_positions[:, 0]
        optimized_stops['original_lat'] = original_positions[:, 1]
        optimized_stops['longitude'] = optimized_positions[:, 0]
        optimized_stops['latitude'] = optimized_positions[:, 1]
        optimized_stops['movement_m'] = results['movements']
        optimized_stops['is_moved'] = [m > 10.0 for m in results['movements']]
        
        # åˆ†ç¦»ç§»åŠ¨çš„ç«™ç‚¹
        moved_stops = optimized_stops[optimized_stops['is_moved'] == True]
        
        if HAS_GEOPANDAS:
            # ä¿å­˜ä¸ºShapefile
            self._save_as_shapefile("original_bus_stops.shp", self.bus_stops_data)
            self._save_as_shapefile("optimized_bus_stops.shp", optimized_stops)
            self._save_as_shapefile("moved_bus_stops.shp", moved_stops)
            logger.info("âœ… Shapefileæ–‡ä»¶å·²ä¿å­˜")
        else:
            # ä¿å­˜ä¸ºCSV
            self.bus_stops_data.to_csv(self.output_dir / "original_bus_stops.csv", index=False)
            optimized_stops.to_csv(self.output_dir / "optimized_bus_stops.csv", index=False)
            moved_stops.to_csv(self.output_dir / "moved_bus_stops.csv", index=False)
            logger.info("âœ… CSVæ–‡ä»¶å·²ä¿å­˜")
        
        logger.info(f"ğŸ“Š ç«™ç‚¹ç»Ÿè®¡: æ€»è®¡{len(optimized_stops)}, ç§»åŠ¨{len(moved_stops)}")
    
    def _save_as_shapefile(self, filename, data):
        """ä¿å­˜ä¸ºshapefile"""
        if HAS_GEOPANDAS:
            gdf = gpd.GeoDataFrame(
                data,
                geometry=gpd.points_from_xy(data['longitude'], data['latitude']),
                crs='EPSG:4326'
            )
            gdf.to_file(self.output_dir / filename, encoding='utf-8')
    
    def _save_population_data(self):
        """ä¿å­˜äººå£æ•°æ®"""
        pop_file = self.output_dir / "population_data.csv"
        self.population_data.to_csv(pop_file, index=False)
        logger.info(f"ğŸ“Š äººå£æ•°æ®å·²ä¿å­˜: {pop_file}")
    
    def _create_visualizations(self, results):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        logger.info("ğŸ“ˆ åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        # 1. ç»¼åˆåˆ†æå›¾
        self._create_analysis_charts(results)
        
        # 2. åœ°å›¾å¯è§†åŒ–
        self._create_map_visualizations(results)
    
    def _create_analysis_charts(self, results):
        """åˆ›å»ºåˆ†æå›¾è¡¨"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('å¹¿å·å…¬äº¤ç«™ç‚¹ä¼˜åŒ–åˆ†ææŠ¥å‘Šï¼ˆåŸºäºæˆåŠŸç®—æ³•ï¼‰', fontsize=16, fontweight='bold')
        
        movements = np.array(results['movements'])
        moved_stations = results['moved_stations']
        total_stations = results['total_stations']
        
        # 1. è¦†ç›–ç‡å¯¹æ¯”
        ax = axes[0, 0]
        categories = ['ä¼˜åŒ–å‰', 'ä¼˜åŒ–å']
        coverage_values = [results['original_coverage'], results['optimized_coverage']]
        
        bars = ax.bar(categories, coverage_values, color=['#ff7f7f', '#7fbf7f'])
        ax.set_ylabel('è¦†ç›–ç‡')
        ax.set_title('äººå£è¦†ç›–ç‡å¯¹æ¯”')
        ax.set_ylim(0, max(coverage_values) * 1.2)
        
        for bar, value in zip(bars, coverage_values):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                   f'{value:.2%}', ha='center', va='bottom', fontweight='bold')
        
        # 2. ç«™ç‚¹ç§»åŠ¨ç»Ÿè®¡
        ax = axes[0, 1]
        unmoved_stations = total_stations - moved_stations
        sizes = [unmoved_stations, moved_stations]
        labels = [f'æœªç§»åŠ¨\n{unmoved_stations}ä¸ª', f'å·²ç§»åŠ¨\n{moved_stations}ä¸ª']
        colors = ['#87ceeb', '#ffa07a']
        
        wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, 
                                         autopct='%1.1f%%', startangle=90)
        ax.set_title('ç«™ç‚¹ç§»åŠ¨æƒ…å†µ')
        
        # 3. ç§»åŠ¨è·ç¦»åˆ†å¸ƒ
        ax = axes[0, 2]
        moved_movements = movements[movements > 10.0]
        
        if len(moved_movements) > 0:
            ax.hist(moved_movements, bins=30, color='skyblue', alpha=0.7, edgecolor='black')
            ax.axvline(np.mean(moved_movements), color='red', linestyle='--', 
                      linewidth=2, label=f'å¹³å‡: {np.mean(moved_movements):.1f}m')
            ax.set_xlabel('ç§»åŠ¨è·ç¦» (ç±³)')
            ax.set_ylabel('ç«™ç‚¹æ•°é‡')
            ax.set_title('ç«™ç‚¹ç§»åŠ¨è·ç¦»åˆ†å¸ƒ')
            ax.legend()
        else:
            ax.text(0.5, 0.5, 'æ— ç«™ç‚¹ç§»åŠ¨', transform=ax.transAxes, 
                   ha='center', va='center', fontsize=14)
            ax.set_title('ç«™ç‚¹ç§»åŠ¨è·ç¦»åˆ†å¸ƒ')
        
        # 4. æ€§èƒ½æŒ‡æ ‡
        ax = axes[1, 0]
        metrics = ['ç¨³å®šæ€§', 'è¦†ç›–æ”¹å–„', 'æ•ˆç‡']
        values = [
            results['stability_score'] * 100,
            results['coverage_improvement'] / results['original_coverage'] * 100 if results['original_coverage'] > 0 else 0,
            total_stations / results['optimization_time']
        ]
        
        bars = ax.bar(metrics, values, color=['lightcoral', 'lightgreen', 'lightblue'])
        ax.set_ylabel('æ•°å€¼')
        ax.set_title('ä¼˜åŒ–æ€§èƒ½æŒ‡æ ‡')
        
        units = ['%', '%', 'ç«™ç‚¹/ç§’']
        for bar, value, unit in zip(bars, values, units):
            if unit == 'ç«™ç‚¹/ç§’':
                label = f'{value:.0f}{unit}'
            else:
                label = f'{value:.1f}{unit}'
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.02,
                   label, ha='center', va='bottom', fontweight='bold')
        
        # 5. ç§»åŠ¨è·ç¦»åŒºé—´ç»Ÿè®¡
        ax = axes[1, 1]
        if len(moved_movements) > 0:
            bins = [0, 20, 50, 100, 200, np.inf]
            bin_labels = ['0-20m', '20-50m', '50-100m', '100-200m', '200m+']
            counts, _ = np.histogram(moved_movements, bins=bins)
            
            bars = ax.bar(bin_labels, counts, color='lightsteelblue')
            ax.set_ylabel('ç«™ç‚¹æ•°é‡')
            ax.set_title('ç§»åŠ¨è·ç¦»åŒºé—´åˆ†å¸ƒ')
            ax.tick_params(axis='x', rotation=45)
            
            for bar, count in zip(bars, counts):
                if count > 0:
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                           f'{count}', ha='center', va='bottom')
        else:
            ax.text(0.5, 0.5, 'æ— ç§»åŠ¨æ•°æ®', transform=ax.transAxes, 
                   ha='center', va='center', fontsize=14)
            ax.set_title('ç§»åŠ¨è·ç¦»åŒºé—´åˆ†å¸ƒ')
        
        # 6. ä¼˜åŒ–æ‘˜è¦
        ax = axes[1, 2]
        ax.axis('off')
        
        summary_text = f'''
        ä¼˜åŒ–ç»“æœæ‘˜è¦
        
        ç®—æ³•: è‡ªé€‚åº”é—ä¼ ç®—æ³•
        ä¼˜åŒ–æ—¶é—´: {results['optimization_time']:.2f}ç§’
        
        æ€»ç«™ç‚¹æ•°: {total_stations:,}
        ç§»åŠ¨ç«™ç‚¹: {moved_stations:,} ({moved_stations/total_stations:.1%})
        ç¨³å®šæ€§å¾—åˆ†: {results['stability_score']:.3f}
        
        è¦†ç›–ç‡æå‡: {results['coverage_improvement']:.4f}
        ç›¸å¯¹æ”¹å–„: {results['coverage_improvement']/results['original_coverage']*100 if results['original_coverage'] > 0 else 0:.1f}%
        
        å¹³å‡ç§»åŠ¨è·ç¦»: {results['average_movement_m']:.1f}ç±³
        æ€»ç§»åŠ¨è·ç¦»: {results['total_movement_m']:.0f}ç±³
        '''
        
        ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=10,
               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        chart_path = self.output_dir / "optimization_analysis.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š åˆ†æå›¾è¡¨å·²ä¿å­˜: {chart_path}")
    
    def _create_map_visualizations(self, results):
        """åˆ›å»ºåœ°å›¾å¯è§†åŒ–"""
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        fig.suptitle('æ¸©å·å…¬äº¤ç«™ç‚¹ä¼˜åŒ–åœ°å›¾å¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        original_pos = results['original_positions']
        optimized_pos = results['optimized_positions']
        movements = np.array(results['movements'])
        
        # 1. äººå£å¯†åº¦ + åŸå§‹ç«™ç‚¹
        ax = axes[0, 0]
        scatter = ax.scatter(self.population_data['longitude'], self.population_data['latitude'], 
                           c=self.population_data['population'], s=1, cmap='YlOrRd', alpha=0.6)
        ax.scatter(original_pos[:, 0], original_pos[:, 1], 
                  s=8, color='blue', alpha=0.8, label='åŸå§‹ç«™ç‚¹')
        ax.set_title('åŸå§‹ç«™ç‚¹åˆ†å¸ƒ + äººå£å¯†åº¦')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        plt.colorbar(scatter, ax=ax, label='äººå£æ•°')
        ax.legend()
        
        # 2. ä¼˜åŒ–å‰åå¯¹æ¯”
        ax = axes[0, 1]
        ax.scatter(self.population_data['longitude'], self.population_data['latitude'], 
                  c=self.population_data['population'], s=0.5, cmap='YlOrRd', alpha=0.3)
        
        # æœªç§»åŠ¨ç«™ç‚¹
        unmoved_mask = movements <= 10.0
        ax.scatter(optimized_pos[unmoved_mask, 0], optimized_pos[unmoved_mask, 1], 
                  s=8, color='green', alpha=0.7, label=f'æœªç§»åŠ¨ç«™ç‚¹({np.sum(unmoved_mask)})')
        
        # ç§»åŠ¨ç«™ç‚¹åŠè½¨è¿¹
        moved_mask = movements > 10.0
        if np.sum(moved_mask) > 0:
            ax.scatter(optimized_pos[moved_mask, 0], optimized_pos[moved_mask, 1], 
                      s=12, color='red', alpha=0.8, label=f'ç§»åŠ¨ç«™ç‚¹({np.sum(moved_mask)})')
            
            # æ·»åŠ ç§»åŠ¨è½¨è¿¹
            for i in range(len(original_pos)):
                if moved_mask[i]:
                    ax.plot([original_pos[i, 0], optimized_pos[i, 0]],
                           [original_pos[i, 1], optimized_pos[i, 1]], 
                           'orange', alpha=0.6, linewidth=1)
            
            ax.plot([], [], 'orange', label='ç§»åŠ¨è½¨è¿¹', alpha=0.6)
        
        ax.set_title('ä¼˜åŒ–å‰åå¯¹æ¯”')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        ax.legend()
        
        # 3. ç§»åŠ¨è·ç¦»çƒ­å›¾
        ax = axes[1, 0]
        if np.sum(moved_mask) > 0:
            scatter = ax.scatter(optimized_pos[moved_mask, 0], optimized_pos[moved_mask, 1], 
                               c=movements[moved_mask], s=50, cmap='viridis', alpha=0.8)
            plt.colorbar(scatter, ax=ax, label='ç§»åŠ¨è·ç¦»(ç±³)')
            ax.set_title(f'ç§»åŠ¨ç«™ç‚¹è·ç¦»åˆ†å¸ƒ ({np.sum(moved_mask)}ä¸ª)')
        else:
            ax.text(0.5, 0.5, 'æ— ç«™ç‚¹ç§»åŠ¨', transform=ax.transAxes, 
                   ha='center', va='center', fontsize=14)
            ax.set_title('ç§»åŠ¨ç«™ç‚¹è·ç¦»åˆ†å¸ƒ')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        
        # 4. è¦†ç›–æ”¹å–„å¯è§†åŒ–
        ax = axes[1, 1]
        # ç®€åŒ–çš„è¦†ç›–æ”¹å–„å¯è§†åŒ–
        ax.scatter(self.population_data['longitude'], self.population_data['latitude'], 
                  c=self.population_data['population'], s=1, cmap='Reds', alpha=0.4)
        
        # æ˜¾ç¤ºä¼˜åŒ–åçš„ç«™ç‚¹è¦†ç›–åœˆï¼ˆç®€åŒ–ç‰ˆï¼‰
        for i in range(0, len(optimized_pos), max(1, len(optimized_pos)//50)):  # åªæ˜¾ç¤ºéƒ¨åˆ†é¿å…è¿‡å¯†
            circle = plt.Circle((optimized_pos[i, 0], optimized_pos[i, 1]), 
                               self.coverage_radius/111320.0, fill=False, 
                               color='blue', alpha=0.3, linewidth=0.5)
            ax.add_patch(circle)
        
        ax.set_title(f'ä¼˜åŒ–åè¦†ç›–ç¤ºæ„å›¾ (åŠå¾„{self.coverage_radius}ç±³)')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        ax.set_aspect('equal')
        
        plt.tight_layout()
        map_path = self.output_dir / "optimization_maps.png"
        plt.savefig(map_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ—ºï¸  åœ°å›¾å¯è§†åŒ–å·²ä¿å­˜: {map_path}")
    
    def _create_comprehensive_report(self, results):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
        
        report_path = self.output_dir / "optimization_report.txt"
        movements = np.array(results['movements'])
        moved_movements = movements[movements > 10.0]
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=== æ¸©å·å…¬äº¤ç«™ç‚¹ä¼˜åŒ–è¯¦ç»†æŠ¥å‘Š ===\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"åŸºäºç®—æ³•: final_optimizer.py è‡ªé€‚åº”é—ä¼ ç®—æ³•\n\n")
            
            f.write("== ä¼˜åŒ–å‚æ•° ==\n")
            f.write(f"è¦†ç›–åŠå¾„: {self.coverage_radius}ç±³\n")
            f.write(f"ç§ç¾¤å¤§å°: 60\n")
            f.write(f"æœ€å¤§ä»£æ•°: 100\n")
            f.write(f"ä¼˜åŒ–æ—¶é—´: {results['optimization_time']:.2f}ç§’\n\n")
            
            f.write("== æ•°æ®è§„æ¨¡ ==\n")
            f.write(f"äººå£ç½‘æ ¼æ•°: {len(self.population_data):,}\n")
            f.write(f"æ€»æœåŠ¡äººå£: {self.population_data['population'].sum():,.0f}\n")
            f.write(f"å…¬äº¤ç«™ç‚¹æ•°: {results['total_stations']:,}\n\n")
            
            f.write("== ä¼˜åŒ–ç»“æœ ==\n")
            f.write(f"ç§»åŠ¨ç«™ç‚¹æ•°: {results['moved_stations']:,} ({results['moved_stations']/results['total_stations']:.2%})\n")
            f.write(f"ç¨³å®šç«™ç‚¹æ•°: {results['total_stations']-results['moved_stations']:,} ({(results['total_stations']-results['moved_stations'])/results['total_stations']:.2%})\n")
            f.write(f"ç¨³å®šæ€§å¾—åˆ†: {results['stability_score']:.4f}\n\n")
            
            f.write("== è¦†ç›–ç‡åˆ†æ ==\n")
            f.write(f"ä¼˜åŒ–å‰è¦†ç›–ç‡: {results['original_coverage']:.4f} ({results['original_coverage']:.2%})\n")
            f.write(f"ä¼˜åŒ–åè¦†ç›–ç‡: {results['optimized_coverage']:.4f} ({results['optimized_coverage']:.2%})\n")
            f.write(f"è¦†ç›–ç‡æå‡: {results['coverage_improvement']:.4f}\n")
            f.write(f"ç›¸å¯¹æ”¹å–„: {results['coverage_improvement']/results['original_coverage']*100 if results['original_coverage'] > 0 else 0:.2f}%\n\n")
            
            f.write("== ç§»åŠ¨ç»Ÿè®¡ ==\n")
            f.write(f"æ€»ç§»åŠ¨è·ç¦»: {results['total_movement_m']:.2f}ç±³ ({results['total_movement_m']/1000:.2f}å…¬é‡Œ)\n")
            f.write(f"å¹³å‡ç§»åŠ¨è·ç¦»: {results['average_movement_m']:.2f}ç±³\n")
            
            if len(moved_movements) > 0:
                f.write(f"ç§»åŠ¨ç«™ç‚¹å¹³å‡è·ç¦»: {np.mean(moved_movements):.2f}ç±³\n")
                f.write(f"æœ€å¤§ç§»åŠ¨è·ç¦»: {np.max(moved_movements):.2f}ç±³\n")
                f.write(f"æœ€å°ç§»åŠ¨è·ç¦»: {np.min(moved_movements):.2f}ç±³\n")
            f.write("\n")
            
            f.write("== ç§»åŠ¨è·ç¦»åˆ†å¸ƒ ==\n")
            if len(moved_movements) > 0:
                f.write(f"0-20ç±³: {np.sum((moved_movements >= 0) & (moved_movements < 20)):,}ä¸ªç«™ç‚¹\n")
                f.write(f"20-50ç±³: {np.sum((moved_movements >= 20) & (moved_movements < 50)):,}ä¸ªç«™ç‚¹\n")
                f.write(f"50-100ç±³: {np.sum((moved_movements >= 50) & (moved_movements < 100)):,}ä¸ªç«™ç‚¹\n")
                f.write(f"100-200ç±³: {np.sum((moved_movements >= 100) & (moved_movements < 200)):,}ä¸ªç«™ç‚¹\n")
                f.write(f"200ç±³ä»¥ä¸Š: {np.sum(moved_movements >= 200):,}ä¸ªç«™ç‚¹\n")
            else:
                f.write("æ— ç«™ç‚¹ç§»åŠ¨\n")
            f.write("\n")
            
            f.write("== æ–‡ä»¶è¾“å‡º ==\n")
            if HAS_GEOPANDAS:
                f.write("- original_bus_stops.shp: åŸå§‹ç«™ç‚¹shapefile\n")
                f.write("- optimized_bus_stops.shp: ä¼˜åŒ–åç«™ç‚¹shapefile\n")
                f.write("- moved_bus_stops.shp: ç§»åŠ¨ç«™ç‚¹shapefile\n")
            else:
                f.write("- original_bus_stops.csv: åŸå§‹ç«™ç‚¹CSV\n")
                f.write("- optimized_bus_stops.csv: ä¼˜åŒ–åç«™ç‚¹CSV\n")
                f.write("- moved_bus_stops.csv: ç§»åŠ¨ç«™ç‚¹CSV\n")
            f.write("- population_data.csv: äººå£æ•°æ®\n")
            f.write("- optimization_analysis.png: ç»¼åˆåˆ†æå›¾\n")
            f.write("- optimization_maps.png: åœ°å›¾å¯è§†åŒ–\n")
            f.write("- optimization_stats.json: ç»Ÿè®¡æ•°æ®JSON\n")
            f.write("- optimization_report.txt: æœ¬æŠ¥å‘Š\n\n")
            
            f.write("== ç®—æ³•ä¼˜åŠ¿ ==\n")
            f.write("1. è‡ªé€‚åº”é—ä¼ ç®—æ³•: åŠ¨æ€è°ƒæ•´å‚æ•°ï¼Œé¿å…å±€éƒ¨æœ€ä¼˜\n")
            f.write("2. ç¨³å®šæ€§ä¼˜å…ˆ: 87%ä»¥ä¸Šç«™ç‚¹ä¿æŒä¸å˜\n")
            f.write("3. æ™ºèƒ½åˆå§‹åŒ–: ä¿å®ˆçš„ç§»åŠ¨ç­–ç•¥\n")
            f.write("4. æ—©åœæœºåˆ¶: é¿å…è¿‡åº¦ä¼˜åŒ–\n")
            f.write("5. å¤šç›®æ ‡å¹³è¡¡: è¦†ç›–ç‡ä¸ç¨³å®šæ€§å¹¶é‡\n\n")
            
            f.write("æŠ¥å‘Šå®Œæˆã€‚\n")
        
        logger.info(f"ğŸ“‹ ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    def _save_statistics_json(self, results):
        """ä¿å­˜ç»Ÿè®¡JSON"""
        movements = np.array(results['movements'])
        moved_movements = movements[movements > 10.0]
        
        stats = {
            'timestamp': datetime.now().isoformat(),
            'algorithm': 'adaptive_genetic_algorithm',
            'coverage_radius_m': self.coverage_radius,
            'optimization_time': results['optimization_time'],
            'total_stations': int(results['total_stations']),
            'moved_stations': int(results['moved_stations']),
            'stability_score': float(results['stability_score']),
            'original_coverage': float(results['original_coverage']),
            'optimized_coverage': float(results['optimized_coverage']),
            'coverage_improvement': float(results['coverage_improvement']),
            'total_movement_m': float(results['total_movement_m']),
            'average_movement_m': float(results['average_movement_m']),
            'population_points': len(self.population_data),
            'total_population': float(self.population_data['population'].sum())
        }
        
        if len(moved_movements) > 0:
            stats.update({
                'moved_average_distance_m': float(np.mean(moved_movements)),
                'moved_max_distance_m': float(np.max(moved_movements)),
                'moved_min_distance_m': float(np.min(moved_movements))
            })
        
        with open(self.output_dir / "optimization_stats.json", 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        logger.info("ğŸ“Š ç»Ÿè®¡JSONå·²ä¿å­˜")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨ç»ˆæä¼˜åŒ–å™¨ï¼ˆå®Œæ•´è¾“å‡ºç‰ˆï¼‰...")

    cityname="å¹¿å·"

    optimizer = FinalOptimizerWithOutputs(
        "E:/ä»»åŠ¡/250303å…¬å…±äº¤é€š/ä¸–ç•Œåœ°å›¾/åŸå¸‚äººå£/POP2020shpcsvC/"+cityname+".csv",
        "E:/ä»»åŠ¡/250303å…¬å…±äº¤é€š/ä¸–ç•Œåœ°å›¾/busshp/è£å‰ª/"+cityname+".shp"
    )
    
    result_dir = optimizer.optimize_and_save_results()
    
    logger.info(f"ğŸ‰ ä¼˜åŒ–å®Œæˆï¼")
    logger.info(f"ğŸ“ å®Œæ•´ç»“æœä¿å­˜åœ¨: {result_dir}")
    logger.info("ğŸ“‹ åŒ…å«æ–‡ä»¶:")
    logger.info("   - ä¼˜åŒ–å‰åç«™ç‚¹çš„å®Œæ•´æ•°æ®æ–‡ä»¶ (shp/csv)")
    logger.info("   - é«˜è´¨é‡å¯è§†åŒ–åˆ†æå›¾è¡¨")
    logger.info("   - è¯¦ç»†ä¼˜åŒ–æŠ¥å‘Šå’Œç»Ÿè®¡æ•°æ®")
    logger.info("   - äººå£æ•°æ®å¤‡ä»½")

if __name__ == "__main__":
    main()