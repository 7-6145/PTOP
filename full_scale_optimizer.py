"""
å…¨è§„æ¨¡ä¼˜åŒ–å™¨ - UltraThinkè¶…å¤§è§„æ¨¡ç‰ˆæœ¬
å¤„ç†æ•´ä¸ªæ¸©å·å¸‚çš„æ‰€æœ‰21465ä¸ªäººå£ç‚¹å’Œ10037ä¸ªç«™ç‚¹
ä½¿ç”¨åˆ†å¸ƒå¼è®¡ç®—å’Œç©ºé—´åˆ†å—ç­–ç•¥
"""

import numpy as np
import pandas as pd
from numba import jit, prange
import logging
import time
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Dict, Any, List, Tuple
import gc
import psutil
import folium
from folium import plugins
import matplotlib.pyplot as plt
from pathlib import Path
import pickle
import json

from data_preprocessing import DataProcessor
from acceleration_utils import fast_population_coverage
from final_optimizer import intelligent_initialization, enhanced_fitness

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FullScaleOptimizer:
    """
    å…¨è§„æ¨¡ä¼˜åŒ–å™¨ - å¤„ç†æ•´ä¸ªæ¸©å·å¸‚æ•°æ®
    
    ç­–ç•¥ï¼š
    1. ç©ºé—´åˆ†å—ï¼šå°†åŸå¸‚åˆ’åˆ†ä¸ºç½‘æ ¼åŒºåŸŸ
    2. å¹¶è¡Œä¼˜åŒ–ï¼šæ¯ä¸ªåŒºåŸŸç‹¬ç«‹ä¼˜åŒ–
    3. å…¨å±€åè°ƒï¼šåŒºåŸŸé—´è¾¹ç•Œåè°ƒ
    4. å†…å­˜ç®¡ç†ï¼šæµå¼å¤„ç†å¤§è§„æ¨¡æ•°æ®
    """
    
    def __init__(self, population_csv_path: str, bus_stops_shp_path: str):
        """åˆå§‹åŒ–å…¨è§„æ¨¡ä¼˜åŒ–å™¨"""
        logger.info("ğŸš€ åˆå§‹åŒ–å…¨è§„æ¨¡ä¼˜åŒ–å™¨...")
        
        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        self._check_system_resources()
        
        # åŠ è½½å®Œæ•´æ•°æ®
        self._load_full_data(population_csv_path, bus_stops_shp_path)
        
        # ç©ºé—´åˆ†å—ç­–ç•¥
        self._create_spatial_blocks()
        
        # ä¼˜åŒ–å‚æ•°
        self.coverage_radius = 0.008  # 800ç±³è¦†ç›–åŠå¾„
        self.n_processes = min(mp.cpu_count(), 8)  # é™åˆ¶å¹¶å‘æ•°é¿å…èµ„æºè€—å°½
        
        logger.info(f"âœ… å…¨è§„æ¨¡ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"   ğŸ“Š æ•°æ®è§„æ¨¡: {len(self.population_data)} äººå£ç‚¹, {len(self.bus_stops_data)} ç«™ç‚¹")
        logger.info(f"   ğŸ—ºï¸  ç©ºé—´åˆ†å—: {self.grid_rows} Ã— {self.grid_cols} = {len(self.spatial_blocks)} ä¸ªåŒºåŸŸ")
        logger.info(f"   ğŸ’» å¹¶è¡Œè¿›ç¨‹: {self.n_processes} ä¸ª")
        logger.info(f"   ğŸ¯ è¦†ç›–åŠå¾„: {self.coverage_radius * 111.32:.0f}ç±³")
    
    def _check_system_resources(self):
        """æ£€æŸ¥ç³»ç»Ÿèµ„æº"""
        memory = psutil.virtual_memory()
        cpu_count = mp.cpu_count()
        
        logger.info(f"ğŸ’» ç³»ç»Ÿèµ„æºæ£€æŸ¥:")
        logger.info(f"   RAM: {memory.total / (1024**3):.1f}GB æ€»å†…å­˜, {memory.available / (1024**3):.1f}GB å¯ç”¨")
        logger.info(f"   CPU: {cpu_count} æ ¸å¿ƒ")
        
        if memory.available < 4 * (1024**3):  # å°äº4GBå¯ç”¨å†…å­˜
            logger.warning("âš ï¸  å¯ç”¨å†…å­˜è¾ƒå°‘ï¼Œå°†ä½¿ç”¨ä¿å®ˆçš„å†…å­˜ç®¡ç†ç­–ç•¥")
        
        if cpu_count < 4:
            logger.warning("âš ï¸  CPUæ ¸å¿ƒæ•°è¾ƒå°‘ï¼Œå¹¶è¡Œæ€§èƒ½å¯èƒ½å—é™")
    
    def _load_full_data(self, population_csv_path: str, bus_stops_shp_path: str):
        """åŠ è½½å®Œæ•´æ•°æ®"""
        logger.info("ğŸ“ åŠ è½½å®Œæ•´æ•°æ®é›†...")
        
        processor = DataProcessor(population_csv_path, bus_stops_shp_path)
        self.population_data, self.bus_stops_data, _ = processor.get_processed_data()
        
        # æ·»åŠ ç©ºé—´ç´¢å¼•
        self.population_data['pop_idx'] = range(len(self.population_data))
        self.bus_stops_data['stop_idx'] = range(len(self.bus_stops_data))
        
        # è®¡ç®—æ€»è¾¹ç•Œ
        self.global_bounds = {
            'min_lon': min(self.population_data['longitude'].min(), 
                          self.bus_stops_data['longitude'].min()),
            'max_lon': max(self.population_data['longitude'].max(), 
                          self.bus_stops_data['longitude'].max()),
            'min_lat': min(self.population_data['latitude'].min(), 
                          self.bus_stops_data['latitude'].min()),
            'max_lat': max(self.population_data['latitude'].max(), 
                          self.bus_stops_data['latitude'].max())
        }
        
        logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ:")
        logger.info(f"   äººå£æ•°æ®: {len(self.population_data)} ç‚¹")
        logger.info(f"   ç«™ç‚¹æ•°æ®: {len(self.bus_stops_data)} ä¸ª")
        logger.info(f"   æœåŠ¡åŒºåŸŸ: {self.global_bounds}")
    
    def _create_spatial_blocks(self):
        """åˆ›å»ºç©ºé—´åˆ†å—"""
        logger.info("ğŸ—ºï¸  åˆ›å»ºç©ºé—´åˆ†å—...")
        
        # æ ¹æ®æ•°æ®åˆ†å¸ƒåŠ¨æ€ç¡®å®šç½‘æ ¼å¤§å°
        lon_range = self.global_bounds['max_lon'] - self.global_bounds['min_lon']
        lat_range = self.global_bounds['max_lat'] - self.global_bounds['min_lat']
        
        # ç›®æ ‡ï¼šæ¯ä¸ªå—åŒ…å«800-1500ä¸ªç«™ç‚¹
        target_stations_per_block = 1200
        total_stations = len(self.bus_stops_data)
        
        n_blocks = max(4, total_stations // target_stations_per_block)
        
        # è®¡ç®—ç½‘æ ¼ç»´åº¦ï¼ˆå°½é‡æ¥è¿‘æ­£æ–¹å½¢ï¼‰
        aspect_ratio = lon_range / lat_range
        self.grid_cols = max(2, int(np.sqrt(n_blocks * aspect_ratio)))
        self.grid_rows = max(2, int(n_blocks / self.grid_cols))
        
        # åˆ›å»ºç½‘æ ¼è¾¹ç•Œ
        lon_step = lon_range / self.grid_cols
        lat_step = lat_range / self.grid_rows
        
        self.spatial_blocks = []
        
        for row in range(self.grid_rows):
            for col in range(self.grid_cols):
                block_bounds = {
                    'min_lon': self.global_bounds['min_lon'] + col * lon_step,
                    'max_lon': self.global_bounds['min_lon'] + (col + 1) * lon_step,
                    'min_lat': self.global_bounds['min_lat'] + row * lat_step,
                    'max_lat': self.global_bounds['min_lat'] + (row + 1) * lat_step,
                    'row': row,
                    'col': col,
                    'block_id': f"block_{row}_{col}"
                }
                
                # ä¸ºè¾¹ç•Œå—æ‰©å±•è¾¹ç•Œï¼ˆå¤„ç†è¾¹ç•Œæ•ˆåº”ï¼‰
                margin = 0.005  # 500ç±³è¾¹ç•Œç¼“å†²
                if col > 0:
                    block_bounds['min_lon'] -= margin
                if col < self.grid_cols - 1:
                    block_bounds['max_lon'] += margin
                if row > 0:
                    block_bounds['min_lat'] -= margin
                if row < self.grid_rows - 1:
                    block_bounds['max_lat'] += margin
                
                # è·å–å—å†…æ•°æ®
                pop_mask = (
                    (self.population_data['longitude'] >= block_bounds['min_lon']) &
                    (self.population_data['longitude'] <= block_bounds['max_lon']) &
                    (self.population_data['latitude'] >= block_bounds['min_lat']) &
                    (self.population_data['latitude'] <= block_bounds['max_lat'])
                )
                
                stop_mask = (
                    (self.bus_stops_data['longitude'] >= block_bounds['min_lon']) &
                    (self.bus_stops_data['longitude'] <= block_bounds['max_lon']) &
                    (self.bus_stops_data['latitude'] >= block_bounds['min_lat']) &
                    (self.bus_stops_data['latitude'] <= block_bounds['max_lat'])
                )
                
                block_pop_data = self.population_data[pop_mask]
                block_stop_data = self.bus_stops_data[stop_mask]
                
                if len(block_stop_data) > 0:  # åªåŒ…å«æœ‰ç«™ç‚¹çš„å—
                    block = {
                        'bounds': block_bounds,
                        'population_data': block_pop_data,
                        'bus_stops_data': block_stop_data,
                        'n_population': len(block_pop_data),
                        'n_stops': len(block_stop_data)
                    }
                    self.spatial_blocks.append(block)
        
        logger.info(f"âœ… ç©ºé—´åˆ†å—å®Œæˆ:")
        for i, block in enumerate(self.spatial_blocks):
            logger.info(f"   åŒºåŸŸ{i+1}: {block['n_population']}äººå£ç‚¹, {block['n_stops']}ç«™ç‚¹")
    
    def optimize_block(self, block_data: Dict) -> Dict[str, Any]:
        """ä¼˜åŒ–å•ä¸ªç©ºé—´å—"""
        block_id = block_data['bounds']['block_id']
        
        try:
            logger.info(f"ğŸ”„ ä¼˜åŒ–åŒºåŸŸ {block_id}...")
            start_time = time.time()
            
            # æå–æ•°æ®
            pop_data = block_data['population_data']
            stop_data = block_data['bus_stops_data']
            
            if len(stop_data) == 0:
                return {'block_id': block_id, 'status': 'empty', 'result': None}
            
            # æ•°æ®é¢„å¤„ç†
            pop_points = pop_data[['longitude', 'latitude']].values
            pop_weights = pop_data['population'].values
            original_positions = stop_data[['longitude', 'latitude']].values
            stop_indices = stop_data['stop_idx'].values
            
            # ç¡®å®šä¼˜åŒ–å‚æ•°ï¼ˆæ ¹æ®å—å¤§å°è°ƒæ•´ï¼‰
            n_stops = len(original_positions)
            
            if n_stops < 50:
                population_size, generations = 20, 30
            elif n_stops < 200:
                population_size, generations = 30, 50
            elif n_stops < 500:
                population_size, generations = 40, 60
            else:
                population_size, generations = 50, 80
            
            # æ‰§è¡Œä¼˜åŒ–
            optimized_positions, best_fitness = self._run_block_optimization(
                original_positions, pop_points, pop_weights,
                population_size, generations
            )
            
            optimization_time = time.time() - start_time
            
            # è®¡ç®—ç»“æœç»Ÿè®¡
            coverage = fast_population_coverage(
                optimized_positions, pop_points, pop_weights, self.coverage_radius
            )
            
            moved_count = 0
            total_movement = 0.0
            
            for i in range(len(original_positions)):
                dx = optimized_positions[i, 0] - original_positions[i, 0]
                dy = optimized_positions[i, 1] - original_positions[i, 1]
                movement = np.sqrt(dx * dx + dy * dy) * 111.32 * 1000  # è½¬æ¢ä¸ºç±³
                
                if movement > 10:  # ç§»åŠ¨è¶…è¿‡10ç±³
                    moved_count += 1
                total_movement += movement
            
            result = {
                'block_id': block_id,
                'status': 'success',
                'optimization_time': optimization_time,
                'n_stops': n_stops,
                'n_population': len(pop_points),
                'coverage': coverage,
                'moved_stations': moved_count,
                'total_movement_m': total_movement,
                'average_movement_m': total_movement / n_stops,
                'best_fitness': best_fitness,
                'original_positions': original_positions,
                'optimized_positions': optimized_positions,
                'stop_indices': stop_indices  # åŸå§‹ç«™ç‚¹ç´¢å¼•
            }
            
            logger.info(f"âœ… åŒºåŸŸ {block_id} å®Œæˆ: "
                       f"è¦†ç›–ç‡{coverage:.3f}, ç§»åŠ¨{moved_count}ç«™ç‚¹, "
                       f"ç”¨æ—¶{optimization_time:.1f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ åŒºåŸŸ {block_id} ä¼˜åŒ–å¤±è´¥: {e}")
            return {'block_id': block_id, 'status': 'error', 'error': str(e)}
    
    def _run_block_optimization(self, original_positions: np.ndarray,
                               pop_points: np.ndarray, pop_weights: np.ndarray,
                               population_size: int, generations: int) -> Tuple[np.ndarray, float]:
        """æ‰§è¡Œå—çº§ä¼˜åŒ–"""
        # ä½¿ç”¨æ”¹è¿›çš„é—ä¼ ç®—æ³•
        population = intelligent_initialization(original_positions, population_size)
        
        best_individual = population[0].copy()
        best_fitness = -np.inf
        
        for generation in range(generations):
            # è®¡ç®—é€‚åº”åº¦
            fitness_scores = np.zeros(population_size)
            
            for i in range(population_size):
                fitness_scores[i] = enhanced_fitness(
                    population[i], original_positions, pop_points, pop_weights, self.coverage_radius
                )
                
                if fitness_scores[i] > best_fitness:
                    best_fitness = fitness_scores[i]
                    best_individual = population[i].copy()
            
            # æ–°ç§ç¾¤ç”Ÿæˆï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œé€‚åº”å¤§è§„æ¨¡å¹¶è¡Œï¼‰
            new_population = np.zeros_like(population)
            
            # ä¿ç•™æœ€ä¼˜ä¸ªä½“
            best_idx = np.argmax(fitness_scores)
            new_population[0] = population[best_idx]
            
            # ç”Ÿæˆæ–°ä¸ªä½“
            for i in range(1, population_size):
                # é”¦æ ‡èµ›é€‰æ‹©
                parent_idx = self._tournament_select(fitness_scores)
                child = population[parent_idx].copy()
                
                # ä¿å®ˆå˜å¼‚
                if np.random.random() < 0.1:
                    child = self._conservative_mutate(child, original_positions)
                
                new_population[i] = child
            
            population = new_population
            
            # æ—©åœæ£€æŸ¥
            if generation > 10 and generation % 10 == 0:
                if best_fitness < 0.5:  # é€‚åº”åº¦è¿‡ä½ï¼Œæå‰åœæ­¢
                    break
        
        return best_individual, best_fitness
    
    def _tournament_select(self, fitness_scores: np.ndarray, tournament_size: int = 3) -> int:
        """é”¦æ ‡èµ›é€‰æ‹©"""
        pop_size = len(fitness_scores)
        candidates = np.random.choice(pop_size, tournament_size, replace=False)
        best_idx = candidates[np.argmax(fitness_scores[candidates])]
        return best_idx
    
    def _conservative_mutate(self, individual: np.ndarray, original_positions: np.ndarray) -> np.ndarray:
        """ä¿å®ˆå˜å¼‚"""
        mutated = individual.copy()
        n_stops = len(individual)
        
        # åªå¯¹5%çš„ç«™ç‚¹å˜å¼‚
        n_mutate = max(1, int(n_stops * 0.05))
        mutate_indices = np.random.choice(n_stops, n_mutate, replace=False)
        
        for idx in mutate_indices:
            # å°å¹…ç§»åŠ¨
            dx = np.random.normal(0, 0.0005)  # çº¦50ç±³æ ‡å‡†å·®
            dy = np.random.normal(0, 0.0005)
            
            mutated[idx, 0] += dx
            mutated[idx, 1] += dy
        
        return mutated
    
    def optimize_full_scale(self, save_results: bool = True) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨è§„æ¨¡ä¼˜åŒ–"""
        logger.info(f"ğŸš€ å¼€å§‹å…¨è§„æ¨¡ä¼˜åŒ–...")
        logger.info(f"   å¤„ç† {len(self.spatial_blocks)} ä¸ªç©ºé—´åŒºåŸŸ")
        logger.info(f"   ä½¿ç”¨ {self.n_processes} ä¸ªå¹¶è¡Œè¿›ç¨‹")
        
        start_time = time.time()
        all_results = []
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰ç©ºé—´å—
        with ProcessPoolExecutor(max_workers=self.n_processes) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_block = {
                executor.submit(self.optimize_block, block): block
                for block in self.spatial_blocks
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_block):
                try:
                    result = future.result()
                    all_results.append(result)
                    
                    if result['status'] == 'success':
                        logger.info(f"âœ… å®Œæˆ {result['block_id']}: "
                                   f"è¦†ç›–ç‡{result['coverage']:.3f}")
                except Exception as e:
                    logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        
        total_time = time.time() - start_time
        
        # åˆå¹¶å’Œåˆ†æç»“æœ
        final_result = self._merge_block_results(all_results, total_time)
        
        # ä¿å­˜ç»“æœ
        if save_results:
            self._save_full_results(final_result)
        
        # æ˜¾ç¤ºæ€»ç»“
        self._display_full_results(final_result)
        
        # æ¸…ç†å†…å­˜
        gc.collect()
        
        return final_result
    
    def _merge_block_results(self, block_results: List[Dict], total_time: float) -> Dict[str, Any]:
        """åˆå¹¶å—ç»“æœ"""
        logger.info("ğŸ”— åˆå¹¶ä¼˜åŒ–ç»“æœ...")
        
        successful_blocks = [r for r in block_results if r['status'] == 'success']
        failed_blocks = [r for r in block_results if r['status'] != 'success']
        
        if not successful_blocks:
            raise RuntimeError("æ‰€æœ‰åŒºåŸŸä¼˜åŒ–éƒ½å¤±è´¥äº†ï¼")
        
        # é‡æ„å…¨å±€ç»“æœ
        total_stations = 0
        total_population = 0
        total_moved = 0
        total_movement = 0.0
        weighted_coverage = 0.0
        
        # æ„å»ºå…¨å±€ä½ç½®æ•°ç»„
        global_original_positions = np.zeros((len(self.bus_stops_data), 2))
        global_optimized_positions = np.zeros((len(self.bus_stops_data), 2))
        
        for block_result in successful_blocks:
            if block_result['status'] != 'success':
                continue
                
            block_stations = block_result['n_stops']
            block_population = block_result['n_population']
            
            # ç´¯è®¡ç»Ÿè®¡
            total_stations += block_stations
            total_population += block_population
            total_moved += block_result['moved_stations']
            total_movement += block_result['total_movement_m']
            
            # åŠ æƒè¦†ç›–ç‡
            weighted_coverage += block_result['coverage'] * block_population
            
            # é‡æ„å…¨å±€ä½ç½®
            stop_indices = block_result['stop_indices']
            original_pos = block_result['original_positions']
            optimized_pos = block_result['optimized_positions']
            
            for i, global_idx in enumerate(stop_indices):
                global_original_positions[global_idx] = original_pos[i]
                global_optimized_positions[global_idx] = optimized_pos[i]
        
        # è®¡ç®—å…¨å±€æŒ‡æ ‡
        global_coverage = weighted_coverage / total_population if total_population > 0 else 0
        stability_score = 1.0 - (total_moved / total_stations)
        average_movement = total_movement / total_stations
        
        result = {
            'optimization_time': total_time,
            'total_blocks_processed': len(successful_blocks),
            'failed_blocks': len(failed_blocks),
            'global_metrics': {
                'total_stations': total_stations,
                'total_population': total_population,
                'moved_stations': total_moved,
                'total_movement_m': total_movement,
                'average_movement_m': average_movement,
                'global_coverage': global_coverage,
                'stability_score': stability_score
            },
            'block_results': successful_blocks,
            'global_positions': {
                'original': global_original_positions,
                'optimized': global_optimized_positions
            },
            'processing_stats': {
                'n_processes': self.n_processes,
                'blocks_per_process': len(self.spatial_blocks) / self.n_processes,
                'average_block_time': total_time / len(successful_blocks) if successful_blocks else 0
            }
        }
        
        return result
    
    def _save_full_results(self, result: Dict[str, Any]):
        """ä¿å­˜å…¨è§„æ¨¡ç»“æœ"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_dir = Path(f"full_scale_results_{timestamp}")
        output_dir.mkdir(exist_ok=True)
        
        logger.info(f"ğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_dir}")
        
        # ä¿å­˜ä¸»ç»“æœï¼ˆä¸åŒ…å«å¤§æ•°ç»„ï¼‰
        main_result = result.copy()
        main_result.pop('global_positions', None)  # ç§»é™¤å¤§æ•°ç»„
        
        with open(output_dir / "optimization_summary.json", 'w', encoding='utf-8') as f:
            json.dump(main_result, f, ensure_ascii=False, indent=2, default=str)
        
        # ä¿å­˜ä½ç½®æ•°æ®
        np.save(output_dir / "original_positions.npy", result['global_positions']['original'])
        np.save(output_dir / "optimized_positions.npy", result['global_positions']['optimized'])
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open(output_dir / "detailed_results.pkl", 'wb') as f:
            pickle.dump(result, f)
        
        logger.info(f"âœ… ç»“æœä¿å­˜å®Œæˆ")
        return output_dir
    
    def _display_full_results(self, result: Dict[str, Any]):
        """æ˜¾ç¤ºå…¨è§„æ¨¡ç»“æœ"""
        logger.info(f"\nğŸ‰ === å…¨è§„æ¨¡ä¼˜åŒ–å®Œæˆ === ğŸ‰")
        logger.info(f"â±ï¸  æ€»ä¼˜åŒ–æ—¶é—´: {result['optimization_time']:.1f}ç§’")
        logger.info(f"ğŸ“Š å¤„ç†åŒºåŸŸæ•°: {result['total_blocks_processed']}")
        logger.info(f"âŒ å¤±è´¥åŒºåŸŸæ•°: {result['failed_blocks']}")
        
        metrics = result['global_metrics']
        logger.info(f"\nğŸ“ˆ å…¨å±€ä¼˜åŒ–æŒ‡æ ‡:")
        logger.info(f"   ğŸ¢ æ€»ç«™ç‚¹æ•°: {metrics['total_stations']:,}")
        logger.info(f"   ğŸ‘¥ æ€»äººå£æ•°: {metrics['total_population']:,}")
        logger.info(f"   ğŸšŒ ç§»åŠ¨ç«™ç‚¹: {metrics['moved_stations']:,} ({metrics['moved_stations']/metrics['total_stations']*100:.1f}%)")
        logger.info(f"   ğŸ“ å¹³å‡ç§»åŠ¨: {metrics['average_movement_m']:.0f}ç±³")
        logger.info(f"   ğŸ¯ å…¨å±€è¦†ç›–ç‡: {metrics['global_coverage']:.4f} ({metrics['global_coverage']*100:.2f}%)")
        logger.info(f"   â­ ç¨³å®šæ€§å¾—åˆ†: {metrics['stability_score']:.4f}")
        
        stats = result['processing_stats']
        logger.info(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
        logger.info(f"   ğŸ’» å¹¶è¡Œè¿›ç¨‹: {stats['n_processes']}")
        logger.info(f"   ğŸ“¦ å¹³å‡åŒºåŸŸå¤„ç†æ—¶é—´: {stats['average_block_time']:.1f}ç§’")
        logger.info(f"   ğŸš€ åŠ é€Ÿæ¯”: {result['optimization_time'] / (stats['average_block_time'] * result['total_blocks_processed']):.1f}x")
    
    def create_full_scale_visualization(self, result: Dict[str, Any], 
                                       sample_ratio: float = 0.1) -> str:
        """åˆ›å»ºå…¨è§„æ¨¡å¯è§†åŒ–åœ°å›¾"""
        logger.info(f"ğŸ—ºï¸  åˆ›å»ºå…¨è§„æ¨¡å¯è§†åŒ–åœ°å›¾...")
        
        # é‡‡æ ·æ˜¾ç¤ºï¼ˆé¿å…åœ°å›¾è¿‡äºå¯†é›†ï¼‰
        pop_sample = self.population_data.sample(
            n=min(2000, int(len(self.population_data) * sample_ratio)),
            random_state=42
        )
        
        stop_sample = self.bus_stops_data.sample(
            n=min(1000, int(len(self.bus_stops_data) * sample_ratio)),
            random_state=42
        )
        
        # åˆ›å»ºåœ°å›¾
        center_lat = (self.global_bounds['min_lat'] + self.global_bounds['max_lat']) / 2
        center_lon = (self.global_bounds['min_lon'] + self.global_bounds['max_lon']) / 2
        
        m = folium.Map(
            location=[center_lat, center_lon],
            zoom_start=10,
            tiles='OpenStreetMap'
        )
        
        # æ·»åŠ äººå£å¯†åº¦çƒ­åŠ›å›¾
        heat_data = [
            [row['latitude'], row['longitude'], row['population']]
            for _, row in pop_sample.iterrows()
        ]
        
        heatmap = plugins.HeatMap(
            heat_data,
            name="äººå£å¯†åº¦",
            min_opacity=0.2,
            radius=8,
            blur=5
        )
        m.add_child(heatmap)
        
        # æ·»åŠ ä¼˜åŒ–åŒºåŸŸè¾¹ç•Œ
        for i, block in enumerate(self.spatial_blocks[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ªåŒºåŸŸ
            bounds = block['bounds']
            folium.Rectangle(
                bounds=[[bounds['min_lat'], bounds['min_lon']], 
                       [bounds['max_lat'], bounds['max_lon']]],
                color='red',
                weight=1,
                fillOpacity=0.1,
                popup=f"åŒºåŸŸ {i+1}: {block['n_stops']}ç«™ç‚¹, {block['n_population']}äººå£"
            ).add_to(m)
        
        # æ·»åŠ åŸå§‹ç«™ç‚¹ï¼ˆé‡‡æ ·ï¼‰
        for _, stop in stop_sample.iterrows():
            folium.CircleMarker(
                location=[stop['latitude'], stop['longitude']],
                radius=3,
                color='blue',
                fillColor='blue',
                fillOpacity=0.6,
                popup=f"åŸå§‹ç«™ç‚¹"
            ).add_to(m)
        
        # æ·»åŠ ç»“æœä¿¡æ¯é¢æ¿
        metrics = result['global_metrics']
        info_html = f"""
        <div style="position: fixed; top: 10px; right: 10px; width: 300px; 
                    background-color: white; border:2px solid grey; z-index:9999; 
                    font-size:12px; padding: 10px; border-radius: 10px;
                    box-shadow: 0 0 15px rgba(0,0,0,0.2);">
        <h4><b>ğŸ† æ¸©å·å…¨å¸‚ä¼˜åŒ–ç»“æœ</b></h4>
        <p><b>æ€»ç«™ç‚¹æ•°:</b> {metrics['total_stations']:,}</p>
        <p><b>æ€»äººå£æ•°:</b> {metrics['total_population']:,}</p>
        <p><b>å…¨å±€è¦†ç›–ç‡:</b> {metrics['global_coverage']:.2%}</p>
        <p><b>ç§»åŠ¨ç«™ç‚¹:</b> {metrics['moved_stations']:,} ({metrics['moved_stations']/metrics['total_stations']*100:.1f}%)</p>
        <p><b>å¹³å‡ç§»åŠ¨:</b> {metrics['average_movement_m']:.0f}ç±³</p>
        <p><b>ç¨³å®šæ€§:</b> {metrics['stability_score']:.3f}</p>
        <p><b>ä¼˜åŒ–æ—¶é—´:</b> {result['optimization_time']:.0f}ç§’</p>
        </div>
        """
        
        m.get_root().html.add_child(folium.Element(info_html))
        
        # ä¿å­˜åœ°å›¾
        map_path = "wenzhou_full_optimization.html"
        m.save(map_path)
        
        logger.info(f"ğŸ—ºï¸  å…¨è§„æ¨¡å¯è§†åŒ–åœ°å›¾å·²ä¿å­˜: {map_path}")
        return map_path


def run_full_scale_optimization():
    """è¿è¡Œå…¨è§„æ¨¡ä¼˜åŒ–"""
    logger.info("ğŸš€ === æ¸©å·å…¨å¸‚å…¬äº¤ç«™ç‚¹ä¼˜åŒ– === ğŸš€")
    
    try:
        # åˆ›å»ºå…¨è§„æ¨¡ä¼˜åŒ–å™¨
        optimizer = FullScaleOptimizer(
            "./populaiton/æ¸©å·_population_grid.csv",
            "./å…¬äº¤ç«™ç‚¹shp/0577æ¸©å·.shp"
        )
        
        # æ‰§è¡Œå…¨è§„æ¨¡ä¼˜åŒ–
        result = optimizer.optimize_full_scale(save_results=True)
        
        # åˆ›å»ºå¯è§†åŒ–
        map_path = optimizer.create_full_scale_visualization(result)
        
        logger.info(f"\nğŸ¯ === ä¼˜åŒ–æ€»ç»“ === ğŸ¯")
        logger.info(f"âœ… æˆåŠŸä¼˜åŒ–æ¸©å·å…¨å¸‚å…¬äº¤ç½‘ç»œ!")
        logger.info(f"ğŸ“Š å¤„ç†äº† {result['global_metrics']['total_stations']:,} ä¸ªç«™ç‚¹")
        logger.info(f"ğŸ‘¥ æœåŠ¡ {result['global_metrics']['total_population']:,} äººå£")
        logger.info(f"ğŸ¯ å®ç° {result['global_metrics']['global_coverage']:.2%} è¦†ç›–ç‡")
        logger.info(f"âš¡ æ€»ç”¨æ—¶ {result['optimization_time']:.0f} ç§’")
        logger.info(f"ğŸ—ºï¸  å¯è§†åŒ–åœ°å›¾: {map_path}")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ å…¨è§„æ¨¡ä¼˜åŒ–å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹å¼ï¼ˆWindowså…¼å®¹ï¼‰
    mp.set_start_method('spawn', force=True)
    
    # è¿è¡Œå…¨è§„æ¨¡ä¼˜åŒ–
    run_full_scale_optimization()