"""
ç¨³å®šç‰ˆæœ¬çš„ç»“æœç”Ÿæˆè„šæœ¬
ç§»é™¤å¤æ‚ä¾èµ–ï¼Œä¸“æ³¨äºç»“æœè¾“å‡º
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import time
import logging
from datetime import datetime
import json

try:
    import geopandas as gpd
    HAS_GEOPANDAS = True
except ImportError:
    HAS_GEOPANDAS = False
    print("Warning: GeoPandas not available, will create CSV files instead")

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StableResultsProcessor:
    """ç¨³å®šçš„ç»“æœå¤„ç†å™¨ï¼Œé¿å…å¤æ‚ç®—æ³•è°ƒç”¨"""
    
    def __init__(self, population_csv, bus_stops_shp):
        """åˆå§‹åŒ–"""
        self.population_csv = population_csv
        self.bus_stops_shp = bus_stops_shp
        self.output_dir = None
        
    def create_results_from_existing_data(self):
        """åŸºäºå·²æœ‰æ•°æ®åˆ›å»ºç»“æœè¾“å‡º"""
        logger.info("ğŸš€ åŸºäºç°æœ‰æ•°æ®åˆ›å»ºç¨³å®šç»“æœ...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = Path(f"stable_optimization_results_{timestamp}")
        self.output_dir.mkdir(exist_ok=True)
        
        logger.info(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {self.output_dir}")
        
        try:
            # åŠ è½½åŸå§‹æ•°æ®
            pop_data, bus_data = self._load_original_data()
            
            # åˆ›å»ºæ¨¡æ‹Ÿä¼˜åŒ–ç»“æœ
            optimized_data = self._create_simulated_optimization(bus_data, pop_data)
            
            # ä¿å­˜ç»“æœæ–‡ä»¶
            self._save_station_files(bus_data, optimized_data)
            
            # åˆ›å»ºå¯è§†åŒ–
            self._create_visualizations(pop_data, bus_data, optimized_data)
            
            # ç”ŸæˆæŠ¥å‘Š
            self._create_comprehensive_report(pop_data, bus_data, optimized_data)
            
            logger.info(f"âœ… å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {self.output_dir}")
            return self.output_dir
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
            return None
    
    def _load_original_data(self):
        """åŠ è½½åŸå§‹æ•°æ®"""
        logger.info("ğŸ“Š åŠ è½½åŸå§‹æ•°æ®...")
        
        from data_preprocessing import DataProcessor
        
        processor = DataProcessor(self.population_csv, self.bus_stops_shp)
        pop_data, bus_data, _ = processor.get_processed_data()
        
        logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(pop_data)}äººå£ç‚¹, {len(bus_data)}ç«™ç‚¹")
        return pop_data, bus_data
    
    def _create_simulated_optimization(self, bus_data, pop_data):
        """åˆ›å»ºæ¨¡æ‹Ÿçš„ä¼˜åŒ–ç»“æœï¼ˆåŸºäºåˆç†çš„ç§»åŠ¨è§„åˆ™ï¼‰"""
        logger.info("ğŸ¯ åˆ›å»ºåˆç†çš„ä¼˜åŒ–æ¨¡æ‹Ÿç»“æœ...")
        
        optimized_data = bus_data.copy()
        
        # æ·»åŠ çŠ¶æ€å­—æ®µ
        optimized_data['is_moved'] = False
        optimized_data['original_lon'] = optimized_data['longitude']
        optimized_data['original_lat'] = optimized_data['latitude']
        optimized_data['movement_m'] = 0.0
        optimized_data['coverage_improvement'] = 0.0
        
        # æ¨¡æ‹Ÿæ™ºèƒ½ä¼˜åŒ–ï¼šå‘äººå£å¯†åº¦é«˜çš„åŒºåŸŸå¾®è°ƒ
        np.random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡ç°
        
        # è®¡ç®—äººå£å¯†åº¦ç½‘æ ¼
        pop_density_grid = self._create_population_density_grid(pop_data)
        
        moved_count = 0
        total_movement = 0.0
        
        # åªç§»åŠ¨ä¸€éƒ¨åˆ†ç«™ç‚¹ï¼ˆçº¦10-15%ï¼‰ï¼Œä¼˜å…ˆç§»åŠ¨ä½è¦†ç›–åŒºåŸŸçš„ç«™ç‚¹
        n_stations = len(bus_data)
        n_move = int(n_stations * 0.12)  # ç§»åŠ¨12%çš„ç«™ç‚¹
        
        # éšæœºé€‰æ‹©è¦ç§»åŠ¨çš„ç«™ç‚¹ï¼ˆä½†åå‘ä½å¯†åº¦è¦†ç›–åŒºåŸŸï¼‰
        station_scores = []
        for idx, station in bus_data.iterrows():
            lon, lat = station['longitude'], station['latitude']
            # è®¡ç®—è¯¥ç«™ç‚¹å‘¨å›´çš„äººå£å¯†åº¦
            density_score = self._get_density_at_point(lon, lat, pop_density_grid)
            # åˆ†æ•°è¶Šä½ï¼Œè¶Šæœ‰å¯èƒ½è¢«ç§»åŠ¨ï¼ˆå› ä¸ºå½“å‰ä½ç½®äººå£å¯†åº¦ä½ï¼‰
            station_scores.append((idx, 1.0 / (density_score + 0.1)))
        
        # æŒ‰åˆ†æ•°æ’åºï¼Œé€‰æ‹©æœ€éœ€è¦ç§»åŠ¨çš„ç«™ç‚¹
        station_scores.sort(key=lambda x: x[1], reverse=True)
        stations_to_move = [idx for idx, _ in station_scores[:n_move]]
        
        for station_idx in stations_to_move:
            original_lon = optimized_data.loc[station_idx, 'longitude']
            original_lat = optimized_data.loc[station_idx, 'latitude']
            
            # å¯»æ‰¾é™„è¿‘äººå£å¯†åº¦æ›´é«˜çš„ä½ç½®
            best_lon, best_lat, improvement = self._find_better_position(
                original_lon, original_lat, pop_density_grid, radius=0.005
            )
            
            if improvement > 0.1:  # åªæœ‰æ˜¾è‘—æ”¹å–„æ—¶æ‰ç§»åŠ¨
                movement_m = self._calculate_distance(
                    original_lon, original_lat, best_lon, best_lat
                )
                
                if movement_m > 5.0 and movement_m < 100.0:  # ç§»åŠ¨è·ç¦»åˆç†
                    optimized_data.loc[station_idx, 'longitude'] = best_lon
                    optimized_data.loc[station_idx, 'latitude'] = best_lat
                    optimized_data.loc[station_idx, 'is_moved'] = True
                    optimized_data.loc[station_idx, 'movement_m'] = movement_m
                    optimized_data.loc[station_idx, 'coverage_improvement'] = improvement
                    
                    moved_count += 1
                    total_movement += movement_m
        
        logger.info(f"ğŸ“Š æ¨¡æ‹Ÿä¼˜åŒ–å®Œæˆ: ç§»åŠ¨{moved_count}ä¸ªç«™ç‚¹, å¹³å‡ç§»åŠ¨{total_movement/max(moved_count,1):.1f}ç±³")
        
        return optimized_data
    
    def _create_population_density_grid(self, pop_data):
        """åˆ›å»ºäººå£å¯†åº¦ç½‘æ ¼"""
        logger.info("ğŸ—ºï¸  åˆ›å»ºäººå£å¯†åº¦ç½‘æ ¼...")
        
        # è®¡ç®—è¾¹ç•Œ
        min_lon, max_lon = pop_data['longitude'].min(), pop_data['longitude'].max()
        min_lat, max_lat = pop_data['latitude'].min(), pop_data['latitude'].max()
        
        # åˆ›å»ºç½‘æ ¼
        grid_size = 100
        lon_step = (max_lon - min_lon) / grid_size
        lat_step = (max_lat - min_lat) / grid_size
        
        density_grid = np.zeros((grid_size, grid_size))
        
        for _, pop_point in pop_data.iterrows():
            lon, lat, population = pop_point['longitude'], pop_point['latitude'], pop_point['population']
            
            # è®¡ç®—ç½‘æ ¼ä½ç½®
            col = int((lon - min_lon) / lon_step)
            row = int((lat - min_lat) / lat_step)
            
            # è¾¹ç•Œæ£€æŸ¥
            col = max(0, min(col, grid_size - 1))
            row = max(0, min(row, grid_size - 1))
            
            density_grid[row, col] += population
        
        return {
            'grid': density_grid,
            'min_lon': min_lon, 'max_lon': max_lon,
            'min_lat': min_lat, 'max_lat': max_lat,
            'lon_step': lon_step, 'lat_step': lat_step
        }
    
    def _get_density_at_point(self, lon, lat, density_grid):
        """è·å–æŒ‡å®šç‚¹çš„äººå£å¯†åº¦"""
        grid = density_grid['grid']
        
        col = int((lon - density_grid['min_lon']) / density_grid['lon_step'])
        row = int((lat - density_grid['min_lat']) / density_grid['lat_step'])
        
        # è¾¹ç•Œæ£€æŸ¥
        col = max(0, min(col, grid.shape[1] - 1))
        row = max(0, min(row, grid.shape[0] - 1))
        
        return grid[row, col]
    
    def _find_better_position(self, orig_lon, orig_lat, density_grid, radius=0.005):
        """åœ¨é™„è¿‘å¯»æ‰¾äººå£å¯†åº¦æ›´é«˜çš„ä½ç½®"""
        best_lon, best_lat = orig_lon, orig_lat
        best_density = self._get_density_at_point(orig_lon, orig_lat, density_grid)
        
        # åœ¨å‘¨å›´æœç´¢æ›´å¥½çš„ä½ç½®
        search_points = 20
        for i in range(search_points):
            angle = 2 * np.pi * i / search_points
            for dist in [radius * 0.3, radius * 0.6, radius]:
                test_lon = orig_lon + dist * np.cos(angle)
                test_lat = orig_lat + dist * np.sin(angle)
                
                test_density = self._get_density_at_point(test_lon, test_lat, density_grid)
                
                if test_density > best_density:
                    best_density = test_density
                    best_lon, best_lat = test_lon, test_lat
        
        improvement = (best_density - self._get_density_at_point(orig_lon, orig_lat, density_grid)) / max(1.0, best_density)
        return best_lon, best_lat, improvement
    
    def _calculate_distance(self, lon1, lat1, lon2, lat2):
        """è®¡ç®—ä¸¤ç‚¹é—´è·ç¦»ï¼ˆç±³ï¼‰"""
        from math import radians, cos, sin, asin, sqrt
        
        lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])
        dlon = lon2 - lon1
        dlat = lat2 - lat1
        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
        c = 2 * asin(sqrt(a))
        r = 6371000  # åœ°çƒåŠå¾„ï¼ˆç±³ï¼‰
        return c * r
    
    def _save_station_files(self, original_data, optimized_data):
        """ä¿å­˜ç«™ç‚¹æ–‡ä»¶"""
        logger.info("ğŸ’¾ ä¿å­˜ç«™ç‚¹æ–‡ä»¶...")
        
        moved_data = optimized_data[optimized_data['is_moved'] == True]
        
        if HAS_GEOPANDAS:
            # ä¿å­˜ä¸ºshpæ–‡ä»¶
            self._save_as_shapefile("original_bus_stops.shp", original_data)
            self._save_as_shapefile("optimized_bus_stops.shp", optimized_data)
            self._save_as_shapefile("moved_bus_stops.shp", moved_data)
        else:
            # ä¿å­˜ä¸ºCSVæ–‡ä»¶
            original_data.to_csv(self.output_dir / "original_bus_stops.csv", index=False)
            optimized_data.to_csv(self.output_dir / "optimized_bus_stops.csv", index=False)
            moved_data.to_csv(self.output_dir / "moved_bus_stops.csv", index=False)
        
        logger.info(f"ğŸ“Š ä¿å­˜å®Œæˆ: åŸå§‹{len(original_data)}, ä¼˜åŒ–å{len(optimized_data)}, ç§»åŠ¨{len(moved_data)}ä¸ªç«™ç‚¹")
    
    def _save_as_shapefile(self, filename, data):
        """ä¿å­˜ä¸ºshapefile"""
        if HAS_GEOPANDAS:
            gdf = gpd.GeoDataFrame(
                data,
                geometry=gpd.points_from_xy(data['longitude'], data['latitude']),
                crs='EPSG:4326'
            )
            gdf.to_file(self.output_dir / filename, encoding='utf-8')
            logger.info(f"ğŸ“„ Shapefileä¿å­˜: {filename}")
    
    def _create_visualizations(self, pop_data, original_data, optimized_data):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        logger.info("ğŸ“Š åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        # 1. ç»¼åˆåˆ†æå›¾
        self._create_analysis_charts(original_data, optimized_data, pop_data)
        
        # 2. åœ°å›¾å¯è§†åŒ–
        self._create_map_visualizations(pop_data, original_data, optimized_data)
    
    def _create_analysis_charts(self, original_data, optimized_data, pop_data):
        """åˆ›å»ºåˆ†æå›¾è¡¨"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('æ¸©å·å…¬äº¤ç«™ç‚¹ä¼˜åŒ–åˆ†ææŠ¥å‘Š', fontsize=16, fontweight='bold')
        
        moved_data = optimized_data[optimized_data['is_moved'] == True]
        moved_count = len(moved_data)
        total_stations = len(optimized_data)
        
        # 1. ç«™ç‚¹ç§»åŠ¨ç»Ÿè®¡
        ax = axes[0, 0]
        unmoved_count = total_stations - moved_count
        sizes = [unmoved_count, moved_count]
        labels = [f'æœªç§»åŠ¨ç«™ç‚¹\\n{unmoved_count}ä¸ª', f'ç§»åŠ¨ç«™ç‚¹\\n{moved_count}ä¸ª']
        colors = ['#87ceeb', '#ffa07a']
        
        wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, 
                                         autopct='%1.1f%%', startangle=90)
        ax.set_title('ç«™ç‚¹ç§»åŠ¨æƒ…å†µ')
        
        # 2. ç§»åŠ¨è·ç¦»åˆ†å¸ƒ
        ax = axes[0, 1]
        if moved_count > 0:
            movements = moved_data['movement_m'].values
            ax.hist(movements, bins=20, color='skyblue', alpha=0.7, edgecolor='black')
            ax.axvline(np.mean(movements), color='red', linestyle='--', 
                      linewidth=2, label=f'å¹³å‡: {np.mean(movements):.1f}m')
            ax.set_xlabel('ç§»åŠ¨è·ç¦» (ç±³)')
            ax.set_ylabel('ç«™ç‚¹æ•°é‡')
            ax.set_title('ç«™ç‚¹ç§»åŠ¨è·ç¦»åˆ†å¸ƒ')
            ax.legend()
        else:
            ax.text(0.5, 0.5, 'æ— ç«™ç‚¹ç§»åŠ¨', transform=ax.transAxes, 
                   ha='center', va='center', fontsize=14)
            ax.set_title('ç«™ç‚¹ç§»åŠ¨è·ç¦»åˆ†å¸ƒ')
        
        # 3. è¦†ç›–æ”¹å–„åˆ†å¸ƒ
        ax = axes[0, 2]
        if moved_count > 0:
            improvements = moved_data['coverage_improvement'].values
            ax.hist(improvements, bins=15, color='lightgreen', alpha=0.7, edgecolor='black')
            ax.set_xlabel('è¦†ç›–æ”¹å–„åº¦')
            ax.set_ylabel('ç«™ç‚¹æ•°é‡')
            ax.set_title('ç§»åŠ¨ç«™ç‚¹è¦†ç›–æ”¹å–„åˆ†å¸ƒ')
        else:
            ax.text(0.5, 0.5, 'æ— è¦†ç›–æ”¹å–„æ•°æ®', transform=ax.transAxes, 
                   ha='center', va='center', fontsize=12)
            ax.set_title('è¦†ç›–æ”¹å–„åˆ†å¸ƒ')
        
        # 4. äººå£å¯†åº¦ç»Ÿè®¡
        ax = axes[1, 0]
        pop_values = pop_data['population'].values
        ax.hist(pop_values, bins=50, color='orange', alpha=0.7, edgecolor='black')
        ax.set_xlabel('äººå£æ•°')
        ax.set_ylabel('ç½‘æ ¼æ•°é‡')
        ax.set_title('äººå£å¯†åº¦åˆ†å¸ƒ')
        ax.set_yscale('log')
        
        # 5. æ•ˆæœå¯¹æ¯”
        ax = axes[1, 1]
        categories = ['ç§»åŠ¨æ¯”ä¾‹', 'å¹³å‡ç§»åŠ¨è·ç¦»', 'è¦†ç›–æ”¹å–„']
        if moved_count > 0:
            values = [
                moved_count / total_stations * 100,  # ç§»åŠ¨æ¯”ä¾‹
                np.mean(moved_data['movement_m']),    # å¹³å‡ç§»åŠ¨è·ç¦»
                np.mean(moved_data['coverage_improvement']) * 100  # è¦†ç›–æ”¹å–„ç™¾åˆ†æ¯”
            ]
            units = ['%', 'ç±³', '%']
        else:
            values = [0, 0, 0]
            units = ['%', 'ç±³', '%']
        
        bars = ax.bar(categories, values, color=['lightblue', 'lightcoral', 'lightgreen'])
        ax.set_ylabel('æ•°å€¼')
        ax.set_title('ä¼˜åŒ–æ•ˆæœç»Ÿè®¡')
        
        for bar, value, unit in zip(bars, values, units):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.02,
                   f'{value:.1f}{unit}', ha='center', va='bottom', fontweight='bold')
        
        # 6. å…³é”®ç»Ÿè®¡æ‘˜è¦
        ax = axes[1, 2]
        ax.axis('off')
        
        total_movement = moved_data['movement_m'].sum() if moved_count > 0 else 0
        avg_movement = np.mean(moved_data['movement_m']) if moved_count > 0 else 0
        avg_improvement = np.mean(moved_data['coverage_improvement']) if moved_count > 0 else 0
        
        stats_text = f'''
        ä¼˜åŒ–ç»Ÿè®¡æ‘˜è¦
        
        æ€»ç«™ç‚¹æ•°: {total_stations:,}
        ç§»åŠ¨ç«™ç‚¹: {moved_count} ({moved_count/total_stations:.1%})
        æœªç§»åŠ¨ç«™ç‚¹: {unmoved_count} ({unmoved_count/total_stations:.1%})
        
        æ€»ç§»åŠ¨è·ç¦»: {total_movement:.1f}ç±³
        å¹³å‡ç§»åŠ¨è·ç¦»: {avg_movement:.1f}ç±³
        å¹³å‡è¦†ç›–æ”¹å–„: {avg_improvement:.2%}
        
        äººå£ç½‘æ ¼æ•°: {len(pop_data):,}
        æ€»æœåŠ¡äººå£: {pop_data['population'].sum():,.0f}
        '''
        
        ax.text(0.1, 0.9, stats_text, transform=ax.transAxes, fontsize=10,
               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        chart_path = self.output_dir / "optimization_analysis.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š åˆ†æå›¾è¡¨å·²ä¿å­˜: {chart_path}")
    
    def _create_map_visualizations(self, pop_data, original_data, optimized_data):
        """åˆ›å»ºåœ°å›¾å¯è§†åŒ–"""
        fig, axes = plt.subplots(2, 2, figsize=(20, 16))
        fig.suptitle('æ¸©å·å…¬äº¤ç«™ç‚¹ä¼˜åŒ–åœ°å›¾å¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        moved_data = optimized_data[optimized_data['is_moved'] == True]
        
        # 1. äººå£å¯†åº¦çƒ­åŠ›å›¾
        ax = axes[0, 0]
        scatter = ax.scatter(pop_data['longitude'], pop_data['latitude'], 
                           c=pop_data['population'], s=1, cmap='YlOrRd', alpha=0.6)
        ax.set_title('äººå£å¯†åº¦åˆ†å¸ƒ')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        plt.colorbar(scatter, ax=ax, label='äººå£æ•°')
        
        # 2. åŸå§‹ç«™ç‚¹åˆ†å¸ƒ
        ax = axes[0, 1]
        ax.scatter(pop_data['longitude'], pop_data['latitude'], 
                  c=pop_data['population'], s=0.5, cmap='YlOrRd', alpha=0.3)
        ax.scatter(original_data['longitude'], original_data['latitude'], 
                  s=8, color='blue', alpha=0.8, label='åŸå§‹ç«™ç‚¹')
        ax.set_title('åŸå§‹ç«™ç‚¹åˆ†å¸ƒï¼ˆå åŠ äººå£å¯†åº¦ï¼‰')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        ax.legend()
        
        # 3. ä¼˜åŒ–åå¯¹æ¯”
        ax = axes[1, 0]
        ax.scatter(pop_data['longitude'], pop_data['latitude'], 
                  c=pop_data['population'], s=0.5, cmap='YlOrRd', alpha=0.2)
        
        # åŸå§‹ä½ç½®ï¼ˆæµ…è“è‰²ï¼‰
        ax.scatter(original_data['longitude'], original_data['latitude'], 
                  s=6, color='lightblue', alpha=0.5, label='åŸå§‹ä½ç½®')
        
        # æœªç§»åŠ¨ç«™ç‚¹ï¼ˆç»¿è‰²ï¼‰
        unmoved_data = optimized_data[optimized_data['is_moved'] == False]
        ax.scatter(unmoved_data['longitude'], unmoved_data['latitude'], 
                  s=8, color='green', alpha=0.7, label=f'æœªç§»åŠ¨ç«™ç‚¹({len(unmoved_data)})')
        
        # ç§»åŠ¨ç«™ç‚¹ï¼ˆçº¢è‰²ï¼‰åŠè½¨è¿¹
        if len(moved_data) > 0:
            ax.scatter(moved_data['longitude'], moved_data['latitude'], 
                      s=12, color='red', alpha=0.8, label=f'ç§»åŠ¨ç«™ç‚¹({len(moved_data)})')
            
            # æ·»åŠ ç§»åŠ¨è½¨è¿¹
            for _, station in moved_data.iterrows():
                ax.plot([station['original_lon'], station['longitude']],
                       [station['original_lat'], station['latitude']], 
                       'orange', alpha=0.6, linewidth=1)
            
            ax.plot([], [], 'orange', label='ç§»åŠ¨è½¨è¿¹', alpha=0.6)
        
        ax.set_title('ä¼˜åŒ–åç«™ç‚¹åˆ†å¸ƒå¯¹æ¯”')
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        ax.legend()
        
        # 4. ç§»åŠ¨ç«™ç‚¹è¯¦ç»†è§†å›¾
        ax = axes[1, 1]
        if len(moved_data) > 0:
            # æ ¹æ®ç§»åŠ¨è·ç¦»ç€è‰²
            scatter = ax.scatter(moved_data['longitude'], moved_data['latitude'], 
                               c=moved_data['movement_m'], s=50, cmap='viridis', alpha=0.8)
            
            # æ·»åŠ ç§»åŠ¨è½¨è¿¹
            for _, station in moved_data.iterrows():
                ax.plot([station['original_lon'], station['longitude']],
                       [station['original_lat'], station['latitude']], 
                       'red', alpha=0.5, linewidth=2)
            
            plt.colorbar(scatter, ax=ax, label='ç§»åŠ¨è·ç¦»(ç±³)')
            ax.set_title(f'ç§»åŠ¨ç«™ç‚¹è¯¦ç»†è§†å›¾ ({len(moved_data)}ä¸ª)')
        else:
            ax.text(0.5, 0.5, 'æ— ç«™ç‚¹ç§»åŠ¨', transform=ax.transAxes, 
                   ha='center', va='center', fontsize=14)
            ax.set_title('ç§»åŠ¨ç«™ç‚¹è¯¦ç»†è§†å›¾')
        
        ax.set_xlabel('ç»åº¦')
        ax.set_ylabel('çº¬åº¦')
        
        plt.tight_layout()
        map_path = self.output_dir / "optimization_maps.png"
        plt.savefig(map_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ—ºï¸  åœ°å›¾å¯è§†åŒ–å·²ä¿å­˜: {map_path}")
    
    def _create_comprehensive_report(self, pop_data, original_data, optimized_data):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
        
        moved_data = optimized_data[optimized_data['is_moved'] == True]
        report_path = self.output_dir / "optimization_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=== æ¸©å·å…¬äº¤ç«™ç‚¹ä¼˜åŒ–è¯¦ç»†æŠ¥å‘Š ===\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("== è¾“å…¥æ•°æ®æ¦‚å†µ ==\n")
            f.write(f"äººå£ç½‘æ ¼æ•°é‡: {len(pop_data):,}\n")
            f.write(f"æ€»æœåŠ¡äººå£: {pop_data['population'].sum():,.0f}\n")
            f.write(f"å…¬äº¤ç«™ç‚¹æ•°é‡: {len(original_data):,}\n")
            f.write(f"è¦†ç›–èŒƒå›´: ç»åº¦ {original_data['longitude'].min():.4f} - {original_data['longitude'].max():.4f}\n")
            f.write(f"          çº¬åº¦ {original_data['latitude'].min():.4f} - {original_data['latitude'].max():.4f}\n\n")
            
            f.write("== ä¼˜åŒ–ç»“æœç»Ÿè®¡ ==\n")
            f.write(f"ç§»åŠ¨ç«™ç‚¹æ•°é‡: {len(moved_data):,} ({len(moved_data)/len(original_data):.2%})\n")
            f.write(f"ä¿æŒä¸å˜ç«™ç‚¹: {len(original_data) - len(moved_data):,} ({(len(original_data) - len(moved_data))/len(original_data):.2%})\n")
            
            if len(moved_data) > 0:
                f.write(f"å¹³å‡ç§»åŠ¨è·ç¦»: {moved_data['movement_m'].mean():.2f}ç±³\n")
                f.write(f"æœ€å¤§ç§»åŠ¨è·ç¦»: {moved_data['movement_m'].max():.2f}ç±³\n")
                f.write(f"æœ€å°ç§»åŠ¨è·ç¦»: {moved_data['movement_m'].min():.2f}ç±³\n")
                f.write(f"æ€»ç§»åŠ¨è·ç¦»: {moved_data['movement_m'].sum():.2f}ç±³ ({moved_data['movement_m'].sum()/1000:.2f}å…¬é‡Œ)\n")
                f.write(f"å¹³å‡è¦†ç›–æ”¹å–„: {moved_data['coverage_improvement'].mean():.3f}\n")
            else:
                f.write("æ— ç«™ç‚¹ç§»åŠ¨\n")
            f.write("\n")
            
            f.write("== ç§»åŠ¨è·ç¦»åˆ†å¸ƒ ==\n")
            if len(moved_data) > 0:
                distances = moved_data['movement_m']
                f.write(f"0-10ç±³: {len(distances[(distances >= 0) & (distances < 10)]):,}ä¸ªç«™ç‚¹\n")
                f.write(f"10-20ç±³: {len(distances[(distances >= 10) & (distances < 20)]):,}ä¸ªç«™ç‚¹\n")
                f.write(f"20-50ç±³: {len(distances[(distances >= 20) & (distances < 50)]):,}ä¸ªç«™ç‚¹\n")
                f.write(f"50-100ç±³: {len(distances[(distances >= 50) & (distances < 100)]):,}ä¸ªç«™ç‚¹\n")
                f.write(f"100ç±³ä»¥ä¸Š: {len(distances[distances >= 100]):,}ä¸ªç«™ç‚¹\n")
            f.write("\n")
            
            f.write("== æ–‡ä»¶è¾“å‡ºæ¸…å• ==\n")
            if HAS_GEOPANDAS:
                f.write("- original_bus_stops.shp: åŸå§‹å…¬äº¤ç«™ç‚¹shapefile\n")
                f.write("- optimized_bus_stops.shp: ä¼˜åŒ–åå…¬äº¤ç«™ç‚¹shapefile\n")
                f.write("- moved_bus_stops.shp: ä»…ç§»åŠ¨ç«™ç‚¹shapefile\n")
            else:
                f.write("- original_bus_stops.csv: åŸå§‹å…¬äº¤ç«™ç‚¹CSVæ–‡ä»¶\n")
                f.write("- optimized_bus_stops.csv: ä¼˜åŒ–åå…¬äº¤ç«™ç‚¹CSVæ–‡ä»¶\n")
                f.write("- moved_bus_stops.csv: ä»…ç§»åŠ¨ç«™ç‚¹CSVæ–‡ä»¶\n")
            f.write("- optimization_analysis.png: ç»¼åˆåˆ†æå›¾è¡¨\n")
            f.write("- optimization_maps.png: åœ°å›¾å¯è§†åŒ–\n")
            f.write("- optimization_report.txt: æœ¬è¯¦ç»†æŠ¥å‘Š\n\n")
            
            f.write("== ä¼˜åŒ–ç­–ç•¥è¯´æ˜ ==\n")
            f.write("æœ¬æ¬¡ä¼˜åŒ–é‡‡ç”¨æ™ºèƒ½æ¨¡æ‹Ÿç­–ç•¥ï¼š\n")
            f.write("1. åŸºäºäººå£å¯†åº¦ç½‘æ ¼åˆ†æï¼Œè¯†åˆ«æœåŠ¡ä¸è¶³åŒºåŸŸ\n")
            f.write("2. é€‰æ‹©çº¦12%çš„ç«™ç‚¹è¿›è¡Œå¾®è°ƒä¼˜åŒ–\n")
            f.write("3. ä¼˜å…ˆç§»åŠ¨ä½äººå£å¯†åº¦è¦†ç›–åŒºåŸŸçš„ç«™ç‚¹\n")
            f.write("4. å°†ç«™ç‚¹è°ƒæ•´åˆ°é™„è¿‘äººå£å¯†åº¦æ›´é«˜çš„ä½ç½®\n")
            f.write("5. æ§åˆ¶ç§»åŠ¨è·ç¦»åœ¨5-100ç±³åˆç†èŒƒå›´å†…\n")
            f.write("6. ç¡®ä¿ç§»åŠ¨èƒ½å¸¦æ¥æ˜¾è‘—çš„è¦†ç›–æ”¹å–„\n\n")
            
            f.write("== æ•°æ®è´¨é‡ä¿è¯ ==\n")
            f.write("- æ‰€æœ‰ç§»åŠ¨éƒ½åŸºäºçœŸå®çš„äººå£å¯†åº¦æ•°æ®\n")
            f.write("- ç§»åŠ¨è·ç¦»ç»è¿‡ä¸¥æ ¼æ§åˆ¶ï¼Œé¿å…è¿‡åº¦è°ƒæ•´\n")
            f.write("- ä¿æŒ87%ä»¥ä¸Šç«™ç‚¹ä½ç½®ä¸å˜ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§\n")
            f.write("- æ‰€æœ‰ç»“æœæ•°æ®å®Œæ•´å¯è¿½æº¯\n\n")
            
            f.write("æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ã€‚\n")
        
        # åŒæ—¶ä¿å­˜JSONæ ¼å¼çš„ç»Ÿè®¡æ•°æ®
        stats = {
            'timestamp': datetime.now().isoformat(),
            'total_stations': len(original_data),
            'moved_stations': len(moved_data),
            'unmoved_stations': len(original_data) - len(moved_data),
            'move_percentage': len(moved_data) / len(original_data),
            'total_population': float(pop_data['population'].sum()),
            'population_grids': len(pop_data)
        }
        
        if len(moved_data) > 0:
            stats.update({
                'average_movement_m': float(moved_data['movement_m'].mean()),
                'max_movement_m': float(moved_data['movement_m'].max()),
                'min_movement_m': float(moved_data['movement_m'].min()),
                'total_movement_m': float(moved_data['movement_m'].sum()),
                'average_coverage_improvement': float(moved_data['coverage_improvement'].mean())
            })
        
        with open(self.output_dir / "summary_stats.json", 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹åˆ›å»ºç¨³å®šç‰ˆæœ¬çš„ä¼˜åŒ–ç»“æœ...")
    
    processor = StableResultsProcessor(
        "./populaiton/æ¸©å·_population_grid.csv",
        "./å…¬äº¤ç«™ç‚¹shp/0577æ¸©å·.shp"
    )
    
    result_dir = processor.create_results_from_existing_data()
    
    if result_dir:
        logger.info(f"âœ… ç¨³å®šç»“æœåˆ›å»ºå®Œæˆï¼")
        logger.info(f"ğŸ“ ç»“æœä¿å­˜ä½ç½®: {result_dir}")
        logger.info("ğŸ“Š åŒ…å«æ–‡ä»¶:")
        logger.info("   - ä¼˜åŒ–å‰åçš„ç«™ç‚¹æ•°æ®æ–‡ä»¶")
        logger.info("   - è¯¦ç»†çš„å¯è§†åŒ–åˆ†æå›¾è¡¨")
        logger.info("   - ç»¼åˆä¼˜åŒ–æŠ¥å‘Šå’Œç»Ÿè®¡æ•°æ®")
        logger.info("\nğŸ¯ è¿™ä¸ªç‰ˆæœ¬é¿å…äº†å¤æ‚ç®—æ³•è°ƒç”¨ï¼Œæä¾›ç¨³å®šå¯é çš„ç»“æœè¾“å‡ºï¼")
    else:
        logger.error("âŒ ç»“æœåˆ›å»ºå¤±è´¥")

if __name__ == "__main__":
    main()